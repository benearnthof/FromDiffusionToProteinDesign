{
  "main": {
    "id": "a47a7315a9d4e6d7",
    "type": "split",
    "children": [
      {
        "id": "03326e7dcab2e068",
        "type": "tabs",
        "children": [
          {
            "id": "e3c52b0fb4bab198",
            "type": "leaf",
            "state": {
              "type": "markdown",
              "state": {
                "file": "Why Transformers Are Sparse and What to Do About It.md",
                "mode": "source",
                "source": false
              },
              "icon": "lucide-file",
              "title": "Why Transformers Are Sparse and What to Do About It"
            }
          },
          {
            "id": "16790fb3a88fc640",
            "type": "leaf",
            "state": {
              "type": "markdown",
              "state": {
                "file": "Chinchilla.md",
                "mode": "source",
                "source": false
              },
              "icon": "lucide-file",
              "title": "Chinchilla"
            }
          }
        ],
        "currentTab": 1
      }
    ],
    "direction": "vertical"
  },
  "left": {
    "id": "fb72f4de4c421c2c",
    "type": "split",
    "children": [
      {
        "id": "0f62c70476ec0176",
        "type": "tabs",
        "children": [
          {
            "id": "1fcff350edde9a71",
            "type": "leaf",
            "state": {
              "type": "file-explorer",
              "state": {
                "sortOrder": "alphabetical",
                "autoReveal": false
              },
              "icon": "lucide-folder-closed",
              "title": "Files"
            }
          },
          {
            "id": "4861d761f75101e4",
            "type": "leaf",
            "state": {
              "type": "search",
              "state": {
                "query": "",
                "matchingCase": false,
                "explainSearch": false,
                "collapseAll": false,
                "extraContext": false,
                "sortOrder": "alphabetical"
              },
              "icon": "lucide-search",
              "title": "Search"
            }
          },
          {
            "id": "82888f79fdb6658e",
            "type": "leaf",
            "state": {
              "type": "bookmarks",
              "state": {},
              "icon": "lucide-bookmark",
              "title": "Bookmarks"
            }
          }
        ]
      }
    ],
    "direction": "horizontal",
    "width": 450.5
  },
  "right": {
    "id": "3c07b9f4148d9bd9",
    "type": "split",
    "children": [
      {
        "id": "290871b4cc455a1b",
        "type": "tabs",
        "children": [
          {
            "id": "09061cfcce4cc017",
            "type": "leaf",
            "state": {
              "type": "backlink",
              "state": {
                "file": "Sparse Attention/A Practical Survey on Faster and Lighter Transformers.md",
                "collapseAll": true,
                "extraContext": true,
                "sortOrder": "alphabetical",
                "showSearch": false,
                "searchQuery": "",
                "backlinkCollapsed": false,
                "unlinkedCollapsed": false
              },
              "icon": "links-coming-in",
              "title": "Backlinks for A Practical Survey on Faster and Lighter Transformers"
            }
          },
          {
            "id": "734892a8abdbd09a",
            "type": "leaf",
            "state": {
              "type": "outgoing-link",
              "state": {
                "file": "Sparse Attention/A Practical Survey on Faster and Lighter Transformers.md",
                "linksCollapsed": false,
                "unlinkedCollapsed": true
              },
              "icon": "links-going-out",
              "title": "Outgoing links from A Practical Survey on Faster and Lighter Transformers"
            }
          },
          {
            "id": "6c8692cf3a814fac",
            "type": "leaf",
            "state": {
              "type": "tag",
              "state": {
                "sortOrder": "frequency",
                "useHierarchy": true,
                "showSearch": false,
                "searchQuery": ""
              },
              "icon": "lucide-tags",
              "title": "Tags"
            }
          },
          {
            "id": "b8975454e1da64a0",
            "type": "leaf",
            "state": {
              "type": "outline",
              "state": {
                "file": "Chinchilla.md",
                "followCursor": false,
                "showSearch": false,
                "searchQuery": ""
              },
              "icon": "lucide-list",
              "title": "Outline of Chinchilla"
            }
          }
        ],
        "currentTab": 3
      }
    ],
    "direction": "horizontal",
    "width": 300
  },
  "left-ribbon": {
    "hiddenItems": {
      "bases:Create new base": false,
      "switcher:Open quick switcher": false,
      "graph:Open graph view": false,
      "canvas:Create new canvas": false,
      "daily-notes:Open today's daily note": false,
      "templates:Insert template": false,
      "command-palette:Open command palette": false
    }
  },
  "active": "16790fb3a88fc640",
  "lastOpenFiles": [
    "Chinchilla.md",
    "Why Transformers Are Sparse and What to Do About It.md",
    "Sparse Attention/Generating Long Sequences with Sparse Transformers.md",
    "GeneralML/Image Transformer.md",
    "GPT-3.md",
    "GPT-4.md",
    "GeneralML/GPT-1.md",
    "GPT-1.md",
    "Improving.md",
    "GPT-2.md",
    "Positional Encoding.md",
    "Modeling High-Dimensional Discrete Data with Multi-Layer Neural Networks.md",
    "The Neural Autoregressive Distribution Estimator.md",
    "GeneralML/Attention Is All You Need.md",
    "Long Short-Term Memory-Networks for Machine Reading.md",
    "Relational inductive biases, deep learning, and graph networks.md",
    "A Decomposable Attention Model for Natural Language Inference.md",
    "PixelCNN.md",
    "GeneralML/Theory and Experiments on Vector Quantized Autoencoders.md",
    "GeneralML/Stand-Alone Self-Attention in Vision Models.md",
    "Sparse Attention/Routing Transformers.md",
    "Sparse Attention/PaLM.md",
    "Measure Theoretic Probability.md",
    "Neural Nets as Distribution Transformers.md",
    "Sparse Attention/FNet Mixing Tokens with Fourier Transforms.md",
    "Sparse Attention/Efficient Transformers.md",
    "Algorithmic Reasoning",
    "Graph Neural Networks",
    "Classic Papers",
    "General CS",
    "Sparse Attention/Untitled",
    "Sparse Attention",
    "Misc",
    "$",
    "GeneralML",
    "Proteomics"
  ]
}