https://staff.fnwi.uva.nl/p.j.c.spreij/onderwijs/master/mtp.pdf
https://web.math.princeton.edu/~js129/PDFs/teaching/MAT425_spring_2025/MAT425_Lecture_Notes.pdf
TODO: take a refresher on transfinite induction https://de.wikipedia.org/wiki/Transfinite_Induktion
# 1 $\sigma$-Algebras and measures

For any non-empty set $S$ we can select some collection of subsets $\Sigma_0 \subset 2^S$.
Such a collection of subsets is called an *algebra* on S if:
	(i) $S \in \Sigma_0$,
	(ii) $E \in \Sigma_0 \Rightarrow E^c \in \Sigma_0$,
	(iii) $E, F \in \Sigma_0 \Rightarrow E \cup F \in \Sigma_0$.
We notice immediately that the empty set $\emptyset$ always belongs to any algebra, since algebras contain the original set $S$ by (i) and are closed under complements (ii), thus the empty set, as the complement of the original set, must be member of any algebra. 

Property (iii) extends to finite unions by induction.

Furthermore, we can show that property (iii) also implies closure under finite intersections and finite set differences, as can be shown:
	$E \cap F=\left(E^c \cup F^c\right)^c$ 
	Leading to:
	$E, F \in \Sigma_0 \Rightarrow E \cap F \in \Sigma_0$,
	and analogously:
	$E \backslash F=E \cap F^c \in \Sigma_0$

### 1.2 Definition of $\sigma$-Algebra

For any nonempty set $S$, a collection of subsets $\Sigma \subset 2^S$ is called a $\sigma$-Algebra on S if it is an algebra and closed under countable unions: 
	$\bigcup_{n=1}^{\infty} E_n \in \Sigma$ for any $E_n \in \Sigma$ $(n = 1, 2, \ldots)$.

A pair $(S, \Sigma)$ is called a measurable space. Elements of $\Sigma$ are called measurable sets. 

#### 1.2.1 $\sigma$-Operator
For any collection $\mathcal{C}$ of subsets of a set $S$ we define the $\sigma$-Operator $\sigma(\mathcal{C})$. This Operator yields the smallest $\sigma$-Algebra that contains $\mathcal{C}$. $\sigma(\mathcal{C})$ is therefore the intersection of all $\sigma$-algebras that contain $\mathcal{C}$. This is very similar to the way we define inner and outer measures in Real Analysis, where we defined the smallest open cover of an interval as the intersection of all open covers of the respective interval. 
We say that $\mathcal{C}$ generates $\Sigma$. 
The union of two $\sigma$-algebras is not necessarily a $\sigma$-algebra. We write
$\Sigma_1 \vee \Sigma_2$ for $\sigma\left(\Sigma_1 \cup \Sigma_2\right)$ instead.
Note: On countable sets we can often just use the power set as a $\sigma$-algebra if we don't explicitly need the smallest $\sigma$-Algebra generated by the countable set.

#### 1.2.2 Borel sets and the Borel $\sigma$-algebra
Let $\mathcal{O}$ be the collection of all open subsets of $\mathbb{R}$ with the usual topology (in which all intervals (a, b) are open). Then we define
$\mathcal{B}:=\sigma(\mathcal{O})$.
As the Borel $\sigma$-Algebra. This notion can get quite abstract for sets in the general sense, but for the real numbers we can construct $\mathcal{B}$ like so: 

### Proposition 1.3 Construction of $\mathcal{B}$

Let $\mathcal{I}=\{(-\infty, x]: x \in \mathbb{R}\}$. Then $\sigma(\mathcal{I})=\mathcal{B}$.
**Proof:** First we show that any half open interval $(-\infty, x]$ can be expressed as a countable union of open intervals: 
	$(-\infty, x]=\cap_n\left(-\infty, x+\frac{1}{n}\right)$ 
Because $\sigma$-Algebras are closed under countable unions and thus, by De Morgan, closed under countable intersections we have shown that $\mathcal{I} \subset \mathcal{B}$ and $\sigma(\mathcal{I}) \subset \mathcal{B}$ since $\sigma(\mathcal{I})$ is the smallest $\sigma$-Algebra that contains $\mathcal{I}$. 
For the reverse inclusion we first observe that any open interval, by the definition of openness, can be expressed as a countable union of half open intervals like so: 
	$(-\infty, x)=\cup_n\left(-\infty, x-\frac{1}{n}\right] \in \sigma(\mathcal{I})$.
Thus, we can express any open interval $(a, b)$ as:
	$(a, b)=(-\infty, b) \backslash(-\infty, a] \in \sigma(\mathcal{I})$.
Where the inclusion in $\sigma(\mathcal{I})$ holds since algebras are closed under set difference.
We can now proceed by using the density, and countability, of the Rational numbers as follows: 
Let $G$ be an arbitrary open set.
By openness there must exist a rational number $\varepsilon_x>0$ for every $x \in G$ such that the open interval $\left(x-2 \varepsilon_x, x+2 \varepsilon_x\right) \subset G$. 
Now, considering the open interval $\left(x-\varepsilon_x, x+\varepsilon_x\right)$ nested in our original interval, we can pick, by density of the Rationals, any rational $q_x$ in this interval. For any such $q_x$ it holds that: $\left|x-q_x\right| \leq \varepsilon_x$.
We can see that: 
	$x \in\left(q_x-\varepsilon_x, q_x+\varepsilon_x\right) \subset \left(x-2 \varepsilon_x, x+2 \varepsilon_x\right) \subset G$
Meaning, that we can express our original $G$ as a countable union of such open intervals: 
	$G \subset \cup_{x \in G}\left(q_x-\varepsilon_x, q_x+\varepsilon_x\right) \subset G$
Where the union is indeed countable, because there exist only countably many rational points $q_x$ and $\varepsilon_x$.
This means in turn, that $G$ is indeed part of the $\sigma$-Algebra of open intervals: 
	$G \in \sigma(\mathcal{I})$  
Which leads us to the desired conclusion:
	$\mathcal{O} \subset \sigma(\mathcal{I})$ and therefore
	$\mathcal{B} \subset \sigma(\mathcal{I})$. (Since $\mathcal{B}$) was defined as the smallest such $\sigma$-Algebra. $\square$

Does any subset of $\mathbb{R}$ fall into $\mathcal{B}$? 
No. Vitali sets are a popular counter example, usually employed in the context of the measure problem, to show that there cannot exist a general measure function that assigns any subset of $\mathbb{R}$ a valid measure. One can show that the cardinality of $\mathcal{B}(\mathbb{R})$ is the same as the cardinality of $\mathbb{R}$ itself, leading to the same conclusion. I skip this proof here, please refer to the linked text for the full proof. The general idea is to show that both the cardinality of $\mathcal{B}(\mathbb{R})$ and the cardinality of the reals are equivalent (intuitively because the reals have the same cardinality as the power set of the natural numbers/the set of all infinite binary sequences, and we generate all substs of $\mathcal{B}(\mathbb{R})$ with a countable number of operations). Thus, when one shows that both of these sets have the same cardinality we notice that the powerset of the reals is of strictly larger cardinality $2^{\mathfrak{c}}$ which implies that there must be some subsets of the reals that are not contained in $\mathcal{B}(\mathbb{R})$.

### 1.2 Measures

In the context of probability we're interested in set functions that assign any subset of a sigma algebra a number ("measurement"). This function should also adhere to certain restrictions.

Let $S$ be any set and $\Sigma$ any $\sigma$-Algebra on $S$. A mapping $\mu: \Sigma \rightarrow[0, \infty]$ is 
	(i) *finitely additive* if $\mu(\emptyset)=0$ and $\mu(E \cup F)=\mu(E)+\mu(F)$ for every pair of disjoint sets $E$ and $F$.
	(ii) *$\sigma$-additive* if $\mu(\emptyset)=0$ and if $\mu\left(\cup_n E_n\right)=\sum_n \mu\left(E_n\right)$ for any sequence of disjoint sets of $\Sigma$ for which its union is also in $\Sigma$. (Which is technically fulfilled by additivity and closure under countable unions already).

#### Definition: Measure Space
Let the tuple $(S, \Sigma)$ be a measurable space. Endowed with a countably additive mapping $\mu: \Sigma \rightarrow[0, \infty]$ we obtain the triple $(S, \Sigma, \mu)$ $-$ a *measure space*.

Measures can have certain useful properties: 
	1. If $\mu(S)<\infty$ we say $\mu$ is finite
	2. If $\mu\left(S_n\right)<\infty$ for $S_n$ measurable sets and $S=\cup_n S_n$ we say $\mu$ is $\sigma$-finite
	3. If $\mu(S)=1$ we say $\mu$ is a *probability measure*

Simple examples for measures: 
* The *counting measure* $\tau$ on $2^{\mathbb{N}}$: $\tau(E)=|E|$ for any $E \in 2^{\mathbb{N}}$ 
* The *Dirac measure* $\delta(E)=\mathbf{1}_E\left(x_0\right)$, for $E \in \Sigma$
* The *Lebesgue measure* on the Borel $\sigma$-Algebra of the reals. 

#### Theorem 1.5: Existence and uniqueness of Lebesgue Measure
There exists a unique measure $\lambda$ on $(\mathbb{R}, \mathcal{B})$ with the property that for any interval $I=(a, b]$ with $a<b$ it holds that $\lambda(I)=b-a$.
**Proof:**
Deferred to later

We will make use of the Lebesgue measure in the Caratheodory Extension Theorem where we will show that $\mathcal{B}$ is no longer the largest $\sigma$-Algebra for which $\lambda$ can be coherently defined. We will extend $\lambda$ to a larger such $\sigma$-Algebra and then prove that by restricting $\lambda$ to our strictly smaller target $\sigma$-Algebra our initial assumptions about $\lambda$ still hold. More on that later.

#### Proposition 1.6: Rules for Measure Calculations
Let $(S, \Sigma, \mu)$ be a measure space. Then for all Sets $E, F \in \Sigma$ the following holds:
	(i) If $E \subset F$, then $\mu(E) \leq \mu(F)$.
	(ii) $\mu(E \cup F) \leq \mu(E)+\mu(F)$.
	(iii) $\mu\left(\cup_{k=1}^n E_k\right) \leq \sum_{k=1}^n \mu\left(E_k\right)$
	If $\mu$ is finite, we also have
	(iv) If $E \subset F$, then $\mu(F \backslash E)=\mu(F)-\mu(E)$.
	(v) $\mu(E \cup F)=\mu(E)+\mu(F)-\mu(E \cap F)$.
**Proof**: In (i) we can split the set $F$ into a disjoint union $F=E \cup(F \backslash E)$. Using the non-negative property of measures we can immediately see that the inequality holds. If $\mu$ is finite property (iv) also directly follows. To prove (ii) we first show that $E\cup F$ can be written as a disjoint Union $E \cup(F \backslash(E \cap F))$ where $E \cap F \subset F$. Applying (i) we directly obtain (ii) and via induction we also obtain (iii). (v) follows, analogous to these considerations, from application of (iv). $\square$

#### Proposition 1.7: Continuity Properties for Measures
Let $(E_n)$ be a sequence of sets in $\Sigma$.
	(i) If the sequence is increasing, with limit $E=\cup_n E_n$, then $\mu\left(E_n\right) \uparrow \mu(E)$ as $n \rightarrow \infty$ 
	(ii) If the sequence is decreasing, with limit $E=\cap_n E_n$ and if $\mu\left(E_n\right)<\infty$ from a certain index on, then $\mu\left(E_n\right) \downarrow \mu(E)$ as $n \rightarrow \infty$.
**Proof:** To prove (i) we define helper sets $D_i$ that are disjoint and thus help us "build up" all sequences of sets $(E_n)$ as disjoint unions of them. We then use [[Measure Theoretic Probability#Proposition 1.6 Rules for Measure Calculations]] to show the statement holds.
To prove (ii) we assume w.l.o.g. that $\mu\left(E_1\right)<\infty$. Again, we define a helper set $F_n$ as $F_n=E_1 \backslash E_n$ and note that $(F_n)$ is an increasing sequence with limit which allows us to use (i) directly to obtain (ii). $\square$

#### Corrolary 1.8: $\sigma$-sub-Additivity
Let $(S, \Sigma, \mu)$ be a measure space. For an arbitrary sequence $(E_n)$ of sets in $\Sigma$, we have $\mu\left(\cup_{n=1}^{\infty} E_n\right) \leq \sum_{n=1}^{\infty} \mu\left(E_n\right)$.
Proof: [[Measure Theoretic Probability#1.6 Exercises]] Exercise 2

### 1.3 Null Sets and Completeness of Measure Spaces

Consider a measure space $(S, \Sigma, \mu)$ and let any $E \in \Sigma$ be such that $\mu(E)=0$. If $N$ is a subset of $E$, then it is fair to suppose that also $\mu(N)=0$. But this only holds if $N \in \Sigma$. 

Intuition: $\Sigma$ may not be "closed" under the measure operation, meaning there might exist some subsets of sets with measure zero that are not measurable under $\mu$.

New terminology: A set $N \subset S$ is called a *null set* or $\mu$-null set, if there exists $E \in \Sigma$ with $E \supset N$ and $\mu(E)=0$. 
The collection of null sets is denoted by $\mathcal{N}$, or $\mathcal{N}_\mu$ since it depends on the choice of $\mu$.
We will show later that $\mathcal{N}$ is a $\sigma$-Algebra and that we can extend $\mu$ to $\bar{\Sigma}=\Sigma \vee \mathcal{N}$.
By extending $\mu$ to $\bar{\Sigma}$ we obtain an extended measure space $(S, \bar{\Sigma}, \bar{\mu})$, which is complete under the measure $\bar{\mu}$ since all $\bar{\mu}$-null sets belong to the $\sigma$-algebra $\bar{\Sigma}$.

### 1.4 $\pi$- and $d$-systems

The contents of the systems of sets we encounter in probability theory and functional analysis are often quite abstract and it can be hard to make constructive statements about the structure of the sets they contain. We will see how some "well behaved" systems of sets allow us to deduce properties of $\Sigma$ from the properties of $\mathcal{C}$ for $\sigma(\mathcal{C})=\Sigma$.

#### Definition 1.10: $\pi$-system

A collection $\mathcal{I}$ of subsets of $S$ is called a $\pi$-system if it is closed under pairwise intersection: 
	$I_1, I_2 \in \mathcal{I}$ implies $I_1 \cap I_2 \in \mathcal{I}$.

Corollary: By induction we can show that this also implies that $pi$-systems are closed under finite intersections.

How is this useful for us, given our stronger definition of $\sigma$-Algebra?
$\sigma$-Algebras allow *countably* many set operations. 
It is possible to disentangle the defining properties of a $\sigma$-Algebra into:
	(i) taking finite intersections
	(ii) the defining properties of a $d$-system / $Dynkin$-system

#### Definition 1.11: $d$-system / $Dynkin$-system

A collection $\mathcal{D}$ of subsets of $S$ is called a $d$-system if the following conditions hold:
	(i) $S \in \mathcal{D}$.
	(ii) If $E, F \in \mathcal{D}$ such that $E \subset F$, then $F \backslash E \in \mathcal{D}$. (note this is a less general assumption than general set differences)
	(iii) If $E_n \in \mathcal{D}$ for $n \in \mathbb{N}$, and $E_n \subset E_{n+1}$ for all $n$, then $\cup_n E_n \in \mathcal{D}$.

#### Proposition 1.12: $\Sigma$ is a $\sigma$-algebra iff it is a $\pi$-system and a $d$-system.

**Proof** Outline: We need to get from the combined properties of pi and dynkin systems to the properties of sigma-Algebras. We already get finite intersections for free. Can we somehow use the "nested difference" property of Dynkin systems with the countable union property to arrive at a full $\sigma$-Algebra? Implication from $\sigma$-Algebra to pi and d-systems is trivial.
First we observe that the "Universe" property is given in d-systems. We use this in combination with (ii) to show that since every subset of a d-system is at least subset of the "universe" set we recover closure under the complement operation. Now we can derive that our system is thus closed under finite unions sine we can express a union as a complement of an intersection of complements, and $\Sigma$ is closed under intersections because it is a $pi$-system. We finally combine this with the third property of dynkin systems to recover that $\Sigma$ must be a $\sigma$-Algebra.
Clarification: We show the countable union property by first defining auxiliary sets $B_n$ like so: 
	$B_1=A_1, \quad B_n=A_n \backslash \bigcup_{k=1}^{n-1} A_k$ for $n \geq 2$.
Where it is clear that each $B_n \subseteq A_n$, the $B_n$ are pairwise disjoint, and $\bigcup_{n=1}^{\infty} A_n=\bigcup_{n=1}^{\infty} B_n$. We only utilize finite intersections, difference and disjoint countable unions, which we all have shown to be valid operations for $\Sigma$. So we can conclude that $B_n \in \Sigma$ for all $n_r$ and finally:
	$\bigcup_{n=1}^{\infty} A_n=\bigcup_{n=1}^{\infty} B_n \in \Sigma$ $\qquad \square$

This leads us straight to Dynkin's Lemma:
#### Proposition 1.13: Dynkin's Lemma: 
Let $\mathcal{I}$ be a $\pi$-system. Then $d(\mathcal{I})=\sigma(\mathcal{I})$.
Proof in the linked notes.
Proposition 1.13 is equivalent to: 
Let $\mathcal{I}$ be a $\pi$-system and $\mathcal{D}$ be a $d$-system. If $\mathcal{I} \subset \mathcal{D}$, then $\sigma(\mathcal{I}) \subset \mathcal{D}$.

Which allows us to show that any finite measure on $\Sigma$ is characterized by its action on a rich enough $\pi$-system. (If we have two **finite** measures $\mu$ and $\nu$ defined on a $\sigma$-Algebra $\Sigma$, and they agree on a $\pi$-system $\mathcal{P} \subseteq \Sigma$ that generates $\Sigma$, then they must coincide on all of $\Sigma$).

#### Theorem 1.15: Uniqueness of Measures

Let $\mathcal{I}$ be a $\pi$-system and $\Sigma=\sigma(\mathcal{I})$. Let $\mu_1$ and $\mu_2$ be finite measures on $\Sigma$ with the properties that $\mu_1(S)=\mu_2(S)$ and that $\mu_1$ and $\mu_2$ coincide on $\mathcal{I}$.  Then $\mu_1=\mu_2$ (on $\Sigma)$. (The measures coincide on the entire sigma Algebra.)
Note: Without finiteness for the measures this theorem does not hold.

### 1.5: Probability Language

In Probability Theory, we are used to the notation $(\Omega, \mathcal{F}, \mathbb{P})$ where we define such a specific instance of a measure space, equipped with a *probability* measure as a *probability space*.
In this context, the measure $\mathbb{P}$ is normed to $\mathbb{P}(\Omega)=1$.  where we refer to $\Omega$ as set of outcomes with the respective *events* being subsets of $\mathcal{F}$. 
**An event is a measurable subset of the set of all outcomes.**

A probability space can be interpreted as a mathematical model of a random experiment. 

In many interesting cases one needs to be careful how one specifies a probability measure to a probability space. Consider infinite sequences of coin tosses. The set of outcomes would take the form $\Omega=\{0,1\}^{\mathbb{N}}$ with each potential outcome being in infinite sequence $\left(\omega_1, \omega_2, \ldots\right)$ with $\omega_n \in\{0,1\}$. Can we just use the powerset of $\Omega$ as a suitable $\sigma$-Algebra?
No! We can show that there is a bijection between the set of all infinite binary sequences (our set of events) and any interval on the real number line, meaning that we run into the same cardinality problem we already encountered when trying to show that there are subsets of $\mathbb{R}$ that are not part of $\mathfrak{B}(\mathbb{R})$. 
How can we find a suitable candidate then?
An alternative would be to define $\mathcal{C}$ as the collection of all events:
	$\mathcal{C}=\left\{\left\{\omega \in \Omega: \omega_n=s\right\}, n \in \mathbb{N}, s \in\{0,1\}\right\}$
Where the n-th entry corresponds to some outcome. 
One can then show that there exists a probability measure on $\mathcal{F}=\sigma(\mathcal{C})$ that recovers all finite cases nicely. Proof: TODO

#### Limsup and Liminf

Interpreting $\mathcal{F}$ as a collection of events one can introduce limsup and liminf as special events.
Consider a sequence of events $E_1, E_2, \dots$ and define:
	$\begin{aligned} \limsup E_n & :=\bigcap_{m=1}^{\infty} \bigcup_{n=m}^{\infty} E_n \\ \liminf E_n & :=\bigcup_{m=1}^{\infty} \bigcap_{n=m}^{\infty} E_n .\end{aligned}$
Limsup is described as the event that the $E_n$ occur infinitely often.
Liminf is the event that the $E_n$ occur eventually.
Proofs/Intuition in exercises. 




### 1.6 Exercises

#### 1.6.2 Prove [[Measure Theoretic Probability#Corrolary 1.8 $ sigma$-sub-Additivity]]







# 2 Existence of Lebesgue Measure

To construct the Lebesgue Measure on the Borel sets of $\mathbb{R}$ we begin by defining a suitable countably additive function on an algebra, extend it to a $\sigma$-Algebra strictly larger than $\mathfrak{B}(\mathbb{R})$ and then show that all desirable properties of our target function still hold when we restrict ourselves back to the Borel-$\sigma$-Algebra of the reals. 
This is the core idea of the *Carathéodory Extension Theorem*.

### 2.1 Outer Measure & Construction

We define an *outer measure* on a set $S$ as a mapping $\mu^*: 2^S \rightarrow [0, \infty]$ that satisfies: 
	(i) $\mu^*(\emptyset)=0$,
	(ii) $\mu^*$ is monotone, i.e. $\mu^*(E) \leq \mu^*(F)$ if $E \subset F$,
	(iii) $\mu^*$ is subadditive, i.e. $\mu^*\left(\bigcup_{n=1}^{\infty} E_n\right) \leq \sum_{n=1}^{\infty} \mu^*\left(E_n\right)$, valid for any sequence of sets $E_n$

We immediately notice that $\mu^*$ is defined on the powerset of $S$ which means that it is defined even for sets that aren't measurable according to our prior definition. Can we somehow restrict this to a valid measure on the Borel sets for example?
Additional note: This is also a slightly different approach to the way Kolmogorov introduces the concept of a general outer measure in chapter 25 section 2 of "Introductory Real Analysis", where he introduces outer measures as the greatest lower bound over all coverings of $E$ by a finite or countable system of rectangles $P_k$. We arrive at measurability by showing that the inner and outer measure of sets are equal to the measure itself, which is conceptually simpler but doesn't allow us to show that we can extend set functions defined on simple subsets to measures on $\sigma$-Algebras.
This is why we take a slightly different approach, which is a bit more abstract.
### 2.2 Definition $\mu$-measurable
Let $\mu^*$ be an outer measure on a set $S$. A subset $E \subset S$ is called $\mu$-measurable if 
	$\mu^*(F)=\mu^*(E \cap F)+\mu^*\left(E^c \cap F\right),\quad \forall F \subset S$ 
This means that a $\mu$-measurable subset "splits" each other subset of $S$ additively. (This will come in handy for the construction of the Carathéodory $\sigma$-Algebra later.)
The class of all such $\mu$-measurable sets, also known as the Carathéodory sets, is denoted by $\Sigma_\mu$.
### 2.3 Carathéodory Criterion
Let $\mu^*$ be an outer measure on a set $S$. Then $\Sigma_\mu$ is a $\sigma$-Algebra and the restricted mapping $\mu: \Sigma_\mu \rightarrow[0, \infty]$ of $\mu^*$ is a measure on $\Sigma_\mu$.

**Proof**: We immediately see that the empty set $\emptyset$ is part of $\Sigma_\mu$ as any intersection with the empty set remains empty, which guarantees that $\emptyset$ is $\mu$-measurable.
Further, $E^c \in \Sigma_\mu$ as soon as $E \in \Sigma_\mu$, meaning that $\Sigma_\mu$ is closed under complements.

Let $E_1, E_2 \in \Sigma_\mu$ and $F \subset S$. The Identity: 
	$F \cap\left(E_1 \cap E_2\right)^c=\left(F \cap E_1^c\right) \cup\left(F \cap\left(E_1 \cap E_2^c\right)\right)$
yields, using the subadditivity of $\mu^*$, 
	$\mu^*\left(F \cap\left(E_1 \cap E_2\right)^c\right) \leq \mu^*\left(F \cap E_1^c\right)+\mu^*\left(F \cap\left(E_1 \cap E_2^c\right)\right)$.
Now, after adding $\mu^*\left(F \cap\left(E_1 \cap E_2\right)\right)$ to both sides and using that $E_1, E_2 \in \Sigma_\mu$ we obtain: 
	$\mu^*\left(F \cap\left(E_1 \cap E_2\right)\right)+\mu^*\left(F \cap\left(E_1 \cap E_2\right)^c\right) \leq \mu^*(F)$,
where we can show equality by using subadditivity of $\mu$ one more time. We have thus shown that $\Sigma_\mu$ is closed under intersections, and is thus an algebra. 

We can then show, by induction and using the monotonicity property of $\mu^*$, that for any pairwise disjoint sequence of sets $E_i$ the following equality holds: 
	$\mu^*(F \cap E)=\sum_{i=1}^{\infty} \mu^*\left(F \cap E_i\right)$

Combining this one last time with monotonicity of $\mu$ for any countable union of sets $U_n=\bigcup_{i=1}^n E_i$ such that $U_n \in \Sigma_\mu$. we can finally show that $\Sigma_\mu$ is closed under countable unions and thus it is a $\sigma$-Algebra. $\square$

We now use Theorem 2.3 to show the existence of Lebesgue measure on $(\mathbb{R}, \mathcal{B})$.
(This is analogous to how Kolmogorov introduces the idea of outer measure in "Introductory Real Analysis). 
Let $E$ be a subset of $\mathbb{R}$. By $\mathcal{I}(E)$ we denote a cover of $E$ consisting of at most countably many open intervals. For any interval $I$, we denote by $\lambda_0(I)$ its ordinary length. We now define a function $\lambda^*$ on $2^\mathbb{R}$ like so:
	$\lambda^*(E)=\inf _{\mathcal{I}(E)} \sum_{I_k \in \mathcal{I}(E)} \lambda_0\left(I_k\right)$.
In Lemma 2.4 of MTP we proceed to show that this is indeed a valid outer measure. The empty set criterion and monotonicity are immediately obvious / or can at least be proven easily by observing the infimum property of this definition. Kolmogorov just proceeds with the analogous definition of inner measure but for full rigor we would need to prove subadditivity.

### Lemma 2.5: 
Any Interval $I_a=(-\infty, a] \quad(a \in \mathbb{R})$ is $\lambda$-measurable. $I_a \in \Sigma_\lambda$. And thus $\mathcal{B} \subset \Sigma_\lambda$.

**Proof**: Let $E \subset \mathbb{R}$. We already know that $\lambda^*$ is subadditive, so we only need to show that for any interval the "additive decomposable"/ Carathéodory Criterion holds: 
	$\lambda^*\left(E \cap I_a\right)+\lambda^*\left(E \cap I_a^c\right)$.
To accomplish this we choose a cover $\mathcal{I}(E)$ such that $\lambda^*(E) \geq\sum_{I \in \mathcal{I}(E)} \lambda^*(I)-\varepsilon$, for any $\varepsilon>0$. Which is valid by the definition of $\lambda^*$ and Lemma 2.4. 
We then use the Carathéodory Criterion for our open cover over the interval:
	$\lambda^*(I)=\lambda^*\left(I \cap I_a\right)+\lambda^*\left(I \cap I_a^c\right)$.
To see that
	$\lambda^*(E) \geq$ $\sum_{I \in \mathcal{I}(E)} \lambda^*\left(I \cap I_a\right)+\lambda^*\left(I \cap I_a^c\right)-\varepsilon$
Which in turn is larger than:
	$\lambda^*\left(E \cap I_a\right)+\lambda^*\left(E \cap I_a^c\right)-\varepsilon$.
By letting $\varepsilon$ become arbitrarily close to zero we obtain the desired equality.

We can now combine these results to arrive at the following theorem:

### Theorem 2.6: Uniqueness of Lebesgue Measure on $\mathcal{B}$
The (restricted) function $\lambda: \mathcal{B} \rightarrow[0, \infty]$ is the unique measure on $\mathcal{B}$ that satisfies $\lambda(I)=\lambda_0(I)$.

**Proof**: We already know that $\lambda$ is a measure on the Carathéodory $\sigma$-Algebra $\Sigma_\lambda$.
By Lemma 2.5 we know that its restriction to the Borel-sets on the reals is also a measure. 
By Lemma 2.4 we also know that $\lambda(I)=\lambda_0(I)$. 
What remains to be proven is the uniqueness of $\lambda$:
Consider we have another measure $\mu$ with the same properties we listed above.
For any $a \in \mathbb{R}$ and $n \in \mathbb{N}$, we have: 
	$(-\infty, a] \cap[-n,+n] \in I$ 
meaning that every such intersection is an interval, hence:
	$\lambda((-\infty, a] \cap[-n,+n])=\mu((-\infty, a] \cap[-n,+n])$.
Because the intervals $(-\infty, a]$ form a $\pi$-system (closed under pairwise intersections) that generates $\mathcal{B}$ we get: 
	$\lambda(B \cap[-n,+n])=\mu(B \cap[-n,+n])$
For any $B\in\mathcal{B}$ and $n\in\mathbb{N}$. 
Every such set is bounded and thus measurable and in the domain of both measures.
In this argument we basically approximate every Borel set by truncating it with the compact intervals $[-n, n]$: 
	$B_n:=B \cap[-n, n]$.
Since both candidate measures $\lambda$ and $\mu$ are $\sigma$-Additive by definition we get that their limits must be equal:
	$\lambda(B)=\lim _{n \rightarrow \infty} \lambda\left(B_n\right), \quad \mu(B)=\lim _{n \rightarrow \infty} \mu\left(B_n\right)$.
	$\lambda(B)=\mu(B)$ 
Because for each $n$ they agree like we've already shown. 
We approximate any (possibly unbounded) Borel set $B$ by an increasing sequence of bounded Borel sets $B_n=B \cap[-n, n].$ 

The sets in the Carathéodory $\sigma$-Algebra $\Sigma_\lambda$ are also called the *Lebesgue-measurable* sets. 

A function $f: \mathbb{R} \rightarrow \mathbb{R}$ is called *Lebesgue-measurable* if the sets $\{f \leq c\}$ are in $\Sigma_\lambda$ for all $c \in \mathbb{R}$.

Are all subsets of $\mathbb{R}$ in $\Sigma_\lambda$? No. With the aforementioned construction of the Vitali sets we can prove this [[Measure Theoretic Probability#2.6 Exercises]]. 
This is a bit more subtle than one might think since we can show that $\Sigma_\lambda$ has the same cardinality as the power set of the reals: 
Consider the Cantor set in $[0, 1]$. By removing the "middle third" interval and then repeating this procedure for each of the remaining "outer thirds" countably many times we obtain a sequence of cantor sets $C_n$ and its limit: 
$C:=\bigcap_{n=1}^{\infty} C_n$
We immediately see that $\lambda(C)=0$. 
On the other hand, we see that $C$ must be uncountable because we can localize every number remaining in it by their ternary expansion $\sum_{k=1}^{\infty} x_k 3^{-k}$ with $x_k \in\{0,2\}$.
By completeness of $\left([0,1], \Sigma_\lambda, \lambda\right)$, every subset of $C$ has Lebesgue measure zero, and the cardinality of the power set of $C$ equals that of the power set of $[0, 1]$.

## 2.2 A general extension theorem

We can generalize the result of Theorem 2.6. In the specific instance above we basically proved that there exists a measure on a $\sigma$-Algebra (in this case on $\mathcal{B}$) that is such that its restriction to a suitable subclass of sets (the intervals) conforms to predetermined behavior. This is also valid in a more general sense.

### 2.7 Carathéodory's Extension Theorem

Let $\Sigma_0$ be an algebra on a set $S$ and let $\mu_0: \Sigma_0 \rightarrow[0, \infty]$ be finitely additive and countably subadditive. Then there exists a mesure $\mu$ defined on $\Sigma=\sigma\left(\Sigma_0\right)$ such that $\mu$ restricted to $\Sigma_0$ coincides with $\mu_0$. 
The measure $\mu$ is thus an extension of $\mu_0$, and this extension is unique if $\mu_0$ is $\sigma$-finite on $\Sigma_0$.

**Proof**: The general Idea is very similar to the proofs in the previous section, we first construct an outer measure on the power set of $S$, then show that by restricting the outer measure to the Carathéodory $\sigma$-Algebra of $S$ we obtain a proper measure. We then show that this measure is unique, concluding the proof.

First we define an outer Measure on $2^S$ like so: 
	$\mu^*(E)=\inf _{\Sigma_0(E)} \sum_{E_k \in \Sigma_0(E)} \mu_0\left(E_k\right)$,
where, like before, we take the infimum over all countable covers of $E$ with elements $E_k$ from $\Sigma_0$.
We've already shown that this is indeed a valid outer measure.

For any $E \in \Sigma_0$ we have:
	$(i)\quad\mu^*(E) \leq \mu_0(E)$.
Now, given any cover of E $\left\{E_1, E_2, \ldots\right\}$ with $E_k \in \Sigma_0$, we have 
	$\mu_0(E) \leq \sum_k \mu_0\left(E \cap E_k\right)$,
because \mu_0$ is countably subadditive and any set $E$ can be split into a countable union $E=\cup_k\left(E \cap E_k\right)$.
Because $\mu_0$ is also finitely additive we obtain: 
	$\mu_0\left(E \cap E_k\right) \leq \mu_0\left(E_k\right)$
Which leads us, by combination with the prior results, to:
	$\mu_0(E) \leq \sum_k \mu_0\left(E_k\right)$.
Now taking the infimum over all covers of $E$ we get:
	$\mu_0(E) \leq \mu^*(E)$, for $E \in \Sigma_0$.
Combining this with $(i)$ we see that both sides must be equal $\mu_0(E)=\mu^*(E)$ and therefore $\mu^*$ must be an extension of $\mu_0$.

TODO: The two remaining steps of the proof (page 14 of MTP) 

Remark: 
Unicity of the extension fails to hold for $\mu_0$ that are not $\sigma$-finite. (Counterexample with infinite sets and the counting measure.)
### 2.6 Exercises


# 3 Measurable Functions and Random Variables

Central goal: Define random variables as *measurable* functions on a probability space and derive their most important properties.

## 3.1 General Setting

Let $(S, \Sigma)$ be a measurable space. Recall that the elements of $\Sigma$ are called the measurable sets. 
$\mathcal{B}=\mathcal{B}(\mathbb{R})$ is the collection of all the Borel sets of $\mathbb{R}$.

### Definition 3.1 Measurable Functions / Mappings
A mapping $h: S \rightarrow \mathbb{R}$ is called *measurable* if all of its preimages $h^{-1}[B]$ are contained in $\Sigma$ for all $B \in \mathcal{B}$: 
	$h^{-1}[B] \in \Sigma \quad \forall B \in \mathcal{B}$ 
One immediately notes that this always depends on the choice of $\sigma$-Algebras. This definition is analogous to the topological definition of continuity, where one defined the property of *continuity* (roughly speaking) by the fact that the preimages of all open sets of the function images are open sets themselves. 
If $S$ is a topological space with a topology $\mathcal{T}$ and if $\Sigma=\sigma(\mathcal{T})$, a measurable function $h$ is also called a *Borel* measurable function. 

Remarks on Notation:
	$\{h \in B\}$ is shorthand for $\{s \in S: h(s) \in B\}$
	$\{h \leq c\}$ is shorthand for $\{s \in S: h(s) \leq c\}$.

### Proposition 3.3: Properties of Measurable Functions $I$

Let $(S, \Sigma)$ be a measurable space and $h: S \rightarrow \mathbb{R}$.
	(i) if $\mathcal{C}$ is a collection of subsets of $\mathbb{R}$ such that they are a generator of the Borel $\sigma$-Algebra: $\sigma(\mathcal{C})=\mathcal{B}$, and if $h^{-1}[C] \in \Sigma$ for all $C \in \mathcal{C}$, then $h$ is measurable. (preimage property)
	(ii) if $\{h \leq c\} \in \Sigma$ for all $c \in \mathbb{R}$, then $h$ is measurable. (boundedness property)
	(iii) if $S$ is topological and $h$ is continuous, then $h$ is measurable with respect to the $\sigma$-Algebra generated by the open sets. In particular, any constant function is measurable. (topological definition of continuity is analogous to preimage property for measurability)
	(iv) If $h$ is measurable and another function $f: \mathbb{R} \rightarrow \mathbb{R}$ is *Borel measurable* ($\mathcal{B} / \mathcal{B}$-measurable), then $f \circ h$ is measurable as well. (composition property)

Proof omitted for brevity, but in essence we only have to show that in (i) when we construct a $\sigma$-Algebra $\mathcal{D}=\left\{B \in \mathcal{B}: h^{-1}[B] \in \Sigma\right\}$ that this is indeed equivalent to $\mathfrak{B}$. (ii) and (iii) then follow from applying (i) and (iv) follows from: Take $B \in \mathcal{B}$, then $f^{-1}[B] \in \mathcal{B}$ because f is Borel measurable. $h$ is measurable itself and thus we obtain: $(f \circ h)^{-1}[B]=h^{-1}\left[f^{-1}[B]\right] \in \Sigma$.
More interestingly, (iv) also generalizes to arbitrary compositions, but we need to keep track of the $\sigma$-Algebras we are mapping from and into.

### Proposition 3.5: Properties of Measurable Functions $II$

We have the following properties: 
	(v) The collection $\Sigma$ of all $\Sigma$-Measurable functions is a vector space and products of measurable functions are measurable aswell.
	(vi) Let $h_n$ be a sequence in $\Sigma$. Then $\inf h_n, \sup h_n, \liminf h_n, \limsup h_n$ are also in $\Sigma$,
	where we extend the range of these functions to $[-\infty, \infty]$. The set $L$, consisting of all $s\in S$ for which $\lim _n h_n(s)$ exists as a finite limit is measurable.

**Proof**: (v) If $h$ is a measurable function and $\lambda$ any real number then $\lambda h$ is also measurable. Why? By application of (ii): 
	$h$ measurable $\Longleftrightarrow \forall c \in \mathbb{R},\{h \leq c\} \in \Sigma$.
we only need to show that 
	$\forall c \in \mathbb{R},\{\lambda h \leq c\} \in \Sigma$.
So we have three cases: $\lambda>0$, $\lambda<0$, and $\lambda=0$, the latter of which is trivial since we already know that any constant function is measurable. For the other two cases we rearrange the inequality:
	$\{\lambda h \leq c\}=\left\{h \leq \frac{c}{\lambda}\right\}$. 
And observe that since $h$ is measurable, $\left\{h \leq \frac{c}{\lambda}\right\} \in \Sigma$, because $\frac{c}{\lambda}$ is just another real number.
We obtain the case for negative $\lambda$ from the equivalent characterization of measurability: 
	$\{x \in X: h(x) \leq c\} \in \Sigma$. where we can swap $\{h<c\},\{h \geq c\},\{h>c\}$ as equivalent properties for measurable functions. 
To then prove that the sum of two measurable functions remains measurable we represent the set $\{f+g \leq c\}$ for any $c \in \mathbb{R}$, as a countable union like so: 
	$\{f+g \leq c\}=\bigcup_{q \in \mathbb{Q}}(\{f \leq q\} \cap\{g \leq c-q\})$.
This holds because $\mathbb{Q}$ is dense in $\mathbb{R}$ and thus, if $f(x)+g(x) \leq c$, there exists $q \in \mathbb{Q}$ such that $f(x) \leq q$ and $g(x) \leq c-q$, yielding exactly the desired property that the sum of these parts is still less than or equal than $c$.
This means that we can represent the preimages of $\{f+g \leq c\}$ as a countable union of intersections, which are operations that will always yield measurable sets. 
Now all that remains to be shown is that the products of measurable functions are measurable:
	If $f$ and $g$ are measurable then $f \cdot g$ is measurable.
We use an algebraic trick to represent this product as a linear combination of squares:
	$f \cdot g=\frac{1}{4}\left[(f+g)^2-(f-g)^2\right]$.
We've already shown that sums, and by symmetry differences, preserve measurability. 
Now we can prove the fact that for any measurable function $h$ squaring preserves measurability analogously to our approach for sums: 
	$\forall c \in \mathbb{R}, \quad\left\{h^2 \leq c\right\} \in \Sigma$ because:
	If $c<0$, then $\left\{h^2 \leq c\right\}=\emptyset$ (which is measurable).
	For $c \geq 0$, observe that:
	$\left\{h^2 \leq c\right\}=\{-\sqrt{c} \leq h \leq \sqrt{c}\}$.
	Or equivalently: 
	$h^2 \leq c \Longleftrightarrow-\sqrt{c} \leq h \leq \sqrt{c}$, 
	where $\{h \leq \sqrt{c}\}$ and $\{h \geq-\sqrt{c}\}$ are both measurable as we've already established. 
	Therefore $\left\{h^2 \leq c\right\}=\{h \leq \sqrt{c}\} \cap\{h \geq-\sqrt{c}\}$ is measurable as intersection of measurable sets.
Combining all three parts of this proofs yields the desired result: The collection $\Sigma$ of $\Sigma$-measurable functions is a vector space. This also concludes exercise 3.1 $\square$

For the proof of statement (vi) we simply use the fact that the infimum can be represented as a countable intersection of measurable sets, which can be applied to supremum and limsup and liminf respectively. 

### Theorem 3.6: Monotone Class Theorem

Let $\mathcal{H}$ be a vector space of bounded functions with the properties: 
	 (i) $1 \in \mathcal{H}$.
	 (ii) If $\left(f_n\right)$ is a nonnegative sequence in $\mathcal{H}$ such that $f_{n+1} \geq f_n$ for all $n$ and $f:=\lim f_n$ bounded, then $f \in \mathcal{H}$.
If, in addition, $\mathcal{H}$ contains the indicator functions of sets in a $\pi$-system $\mathcal{I}$ then $\mathcal{H}$ contains all bounded $\sigma(\mathcal{I})$-measurable functions. 

Intuition: $\mathcal{H}$ is a vector space e.g. closed under linear combinations (i) **and** it is closed under **bounded pointwise monotone limits** (ii).
This is useful because often it is easier to check closure under monotone limits than it is to verify closure under countable unions, intersections, and complements directly. With this theorem we can "bootstrap" a small class of sets/functions up to the entire $\sigma$-Algebra. 
* MCT allows us to prove that certain operations preserve measurability
* MCT allows us to extend properties verified for simple functions to all measurable functions
(We will define *simple* functions later)
This is very useful for later theorems like Monotone Convergence Theorem, Dominated Convergence Theorem, proving closure properties of measurable functions etc.

## 3.2 Random Variables

We now consider a set of outcomes $\Omega$ and a $\sigma$-Algebra $\mathcal{F}$ of events defined on it. In this setting Definition 3.1 (Measurable Functions/Mappings) takes the following form:

### Definition 3.7: Random Variable
A function $X: \Omega \rightarrow \mathbb{R}$ is called a *random variable* if it is $(\mathcal{F})$-measurable. 

We denote random variables by capital letters. By definition, random variables are nothing but measurable functions with respect to a given $\sigma$-Algebra $\mathcal{F}$.

Given 
	$X: \Omega \rightarrow \mathbb{R}$, 
let 
	$\sigma(X)=\left\{X^{-1}[B]: B \in \mathcal{B}\right\}$.
Then 
	$\sigma(X)$ is a $\sigma$-Algebra and $X$ a random variable in the sense of definition 3.7 iff $\sigma(X) \subset \mathcal{F}$.
(The $\sigma$-Algebra generated by a random variable.)
The proof is pretty straight forward, we already know by construction that $\sigma(X)$ is a $\sigma$-Algebra the minimal property is also easy to verify. 
This relates to Exercise 3.2 as we can show that the pi-system $\Pi(X):=\{\{X \leq x\}: x \in \mathbb{R}\}$ generates the Borel sigma algebra. The cumulative distribution function of a random variable X is defined as:
	$F_X(x):=P(X \leq x)=P(\{\omega: X(\omega) \leq x\})$.
Since $\{X \leq x\}$ are precisely the sets in the pi-system that generates $\sigma(X)$ the entire distribution of $X$ is determined by the probabilities of these threshold sets.

### Proposition 3.8: Distribution Function of a Random Variable
The *distribution function* of a random variable is the function: 
	$F: \mathbb{R} \rightarrow[0,1]$, given by $F(x) = \mu((-\infty, x])=\mathbb{P}(X \leq x)$
It is: 
	(i) right coninuous
	(ii) non-decreasing
	(iii) satisfies: $\lim _{x \rightarrow \infty} F(x)=1$ and $\lim _{x \rightarrow-\infty} F(x)=0$.
	(iv) has at most countably many discontinuities

Proof idea for (iv): We know that F is bounded from above and below. Each discontinuity must result in a positive jump > 0. We can only fit countably many such jumps into $[0, 1]$.

### Proposition 3.9: Distribution Functions Fully Describe Probability Distributions

Let $\mu_1$ and $\mu_2$ be probability measures on $\mathcal{B}$. Let $F_1$ and $F_2$ be corresponding distribution functions. If $F_1(x) = F_2(x)$ for all $x$, then $\mu_1 = \mu_2$.
**Proof:** Again, we refer to exercise 3.2 where we prove that the $\pi$-System $\mathcal{I}=\{(-\infty, x]: x \in \mathbb{R}\}$ generates the Borel-$\sigma$-Algebra and invoke Theorem [[Measure Theoretic Probability#Theorem 1.15 Uniqueness of Measures]].

Therefore we have shown, that for any random variable $X$, its distribution, as in the *collection of all probabilities* $\mathbb{P}(X \in B)$ with $B \in \mathcal{B}$, is fully determined by its respective distribution function $F_X$.

We call *any* function on $\mathbb{R}$ with the properties given in Proposition 3.8 a distribution function. Any distribution function is measurable (by their non-decreasing property and the fact that all sets $\{F \geq c\}$ are intervals and thus in $\mathcal{B}$).
We will show in theorem 3.10 that for any distribution function $F$,  it is possible to construct a random variable on some probability space $(\Omega, \mathcal{F}, \mathbb{P})$, whose distribution function equals F. This theorem is based on the existence of the Lebesgue measure $\lambda$ on the Borel sets $\mathcal{B}[0,1]$ of $[0,1]$.
[[Measure Theoretic Probability#Theorem 1.5 Existence and uniqueness of Lebesgue Measure]].
What does this mean in practice? 

Consider: $(\Omega, \mathcal{F}, \mathbb{P})=([0,1], \mathcal{B}[0,1], \lambda)$. Let $U: \Omega \rightarrow[0,1]$ be the identity map. 
The distribution function $F^U$ of $U$ satisfies
	$F^U(x) = x$ for $x \in[0,1]$ and so 
	$\mathbb{P}(a<U \leq b)=F^U(b)-F^U(a)=b-a$ for $a, b \in[0,1]$ with $a \leq b$.
Hence the distribution function $F^U$ corresponds to a probability measure on $([0,1], \mathcal{B}[0,1])$ and there exists a random variable $U$ on this space such that $U$ has $F^U$ as its distribution function. 
This random variable is said to have the standard uniform distribution. 

### Theorem 3.10: Skorokhod's Representation Theorem
Let F be a distribution function on $\mathbb{R}$. Then there exists a probability space and a random variable $X: \Omega \rightarrow \mathbb{R}$ such that $F$ is the distribution function of $X$.

**Proof:** Exercise 3.6 For the continuous and strictly increasing case

## 3.3 Independence

In basic probability theory we defined pairwise independence of evens $E, F \in \mathcal{F}$ by the product rule: $\mathbb{P}(E \cap F)=\mathbb{P}(E) \mathbb{P}(F)$. 
We now want to generalize this notion of independence to independence of sequences of events and independence of sequences of $\sigma$-Algebras. 

### Definition 3.11: Independence
Independence for $\sigma$-Algebras, random variables, and events:
	(i) A sequence of $\sigma$-algebras $\mathcal{F}_1, \mathcal{F}_2, \ldots$ is called independent, if for every $n$ it holds that $\mathbb{P}\left(E_1 \cap \cdots \cap E_n\right)=\prod_{i=1}^n \mathbb{P}\left(E_i\right)$, for all choices $E_i \in \mathcal{F}_i$ $(i=1, \ldots, n)$.
	(ii) A sequence of random variables $X_1, X_2, \dots$ is called independent if the $\sigma$-algebras $\sigma\left(X_1\right), \sigma\left(X_2\right), \ldots$ are independent. 
	(iii) A sequence of events $E_1, E_2, \ldots$ is called independent if th erandom variables $\mathbf{1}_{E_1}, \mathbf{1}_{E_2}, \ldots$ are independent. 

This definition also applies to finite sequences. If follows that two $\sigma$-Algebras $\mathcal{F}_1$ and $\mathcal{F}_2$ are independent if:
	$\mathbb{P}\left(E_1 \cap E_2\right)=\mathbb{P}\left(E_1\right) \mathbb{P}\left(E_2\right)$ for all $E_1 \in \mathcal{F}_1$ and $E_2 \in \mathcal{F}_2$.
To check the independence of two $\sigma$-Algebras, theorem 1.15 is helpful once again:
### Proposition 3.12 Independence of $\sigma$-Algebras
Let $\mathcal{I}$ and $\mathcal{J}$ be $\pi$-systems and suppose that for all $I \in \mathcal{I}$ and $J \in \mathcal{J}$ the product rule $\mathbb{P}(I \cap J)=\mathbb{P}(I) \mathbb{P}(J)$ holds. Then the $\sigma$-algebras $\sigma(\mathcal{I})$ and $\sigma(\mathcal{J})$ are independent.

**Proof**: Let $\mathcal{G}=\sigma(\mathcal{I}) \text { and } \mathcal{H}=\sigma(\mathcal{J}) .$ 
We define on each $I \in \mathcal{I}$ the *finite measures* $\mu_I$ and $\nu_I$ on $\mathcal{H}$ by $\mu_I(H)=\mathbb{P}(H \cap I)$ and $\nu_I(H)=\mathbb{P}(H) \mathbb{P}(I)(H \in \mathcal{H})$.
When do these measures coincide? 
The product rule holds and since they are both $\pi$-systems this holds in the finite case.
(pi-systems closed under intersections).
Assuming now that $\mu_I(\Omega)=\mathbb{P}(I)=\nu_I(\Omega)$, we see that $\mu_I$ and $\nu_I$ coincide on $\mathcal{J}$.
Using theorem 1.15 we know that they must coincide for all H: $\mu_I(H)=\nu_I(H)$ for all $H \in \mathcal{H}$.
Now repeating these steps with swapped finite measures $\mu^H$ and $\nu^H$: $\mu^H(G)=\mathbb{P}(G \cap H)$ and $\nu^H(G)=\mathbb{P}(G) \mathbb{P}(H)$. We get the analogous result for $\mathcal{I}$. $\quad \square$

Why is this important? 
$\sigma$-Algebras are not easy to work with and can be quite abstract like we outlined in earlier discussions. Proposition 3.12 allows us to prove independence on the generating systems of sets that are in most cases much more manageable. 
A simple example (that kind of seems circular because we use i.i.d. to use the product rule to prove independence): 
Suppose we have i.i.d. random variables $X_1, X_2, \ldots, X_n$.
- The sigma-algebra generated by $X_i$ is $\sigma\left(X_i\right)$.
- This is generated by sets of the form $\left\{X_i \in A_i\right\}$, where $A_i \in \mathcal{B}(\mathbb{R})$.
Now we can form a $\pi$-System like so: 
	$\mathcal{I}_i:=\left\{\left\{X_i \in A_i\right\}: A_i \in \mathcal{B}(\mathbb{R})\right\} .$
And only have to prove:
	$\mathbb{P}\left(X_1 \in A_1, X_2 \in A_2, \ldots, X_n \in A_n\right)=\prod_{i=1}^n \mathbb{P}\left(X_i \in A_i\right) .$ 
In order to verify that the underlying $\sigma$-Algebras and by extension random variables are independent. Better examples will follow.

### Corollary 3.13
Let $X_1, X_2$ be random variables defined on some probability space $(\Omega, \mathcal{F}, \mathbb{P})$.
Then $X_1$ and $X_2$ are independent iff:
$\mathbb{P}\left(\left\{X_1 \leq x_1\right\} \cap\left\{X_2 \leq x_2\right\}\right) = \mathbb{P}\left(X_1 \leq\right. \left.x_1\right) \mathbb{P}\left(X_2 \leq x_2\right)$ for all $x_1, x_2 \in \mathbb{R}$.

**Proof:** Combining proposition 3.12 with exercise 3.2.

### Lemma 3.14: Borel-Cantelli

(i) Let $\left(E_n\right)_{n \geq 1}$ be a sequence of events in a probability space $(\Omega, \mathcal{F}, \mathbb{P})$.
- Suppose:

$$
\sum_{n=1}^{\infty} \mathbb{P}\left(E_n\right)<\infty
$$

- Then:

$$
\mathbb{P}\left(\limsup _{n \rightarrow \infty} E_n\right)=0,
$$

i.e., with probability 1 , only finitely many of the events $E_n$ occur.
If the total sum of the event probabilities is finite then the evens cannot keep happening forever.
This is (intuitively) similar to the proof that a distribution function can only have countably many discontinuities: Every time an event happens, it requires some non-zero amount of probability. If the "total available probability" is finite, then the total number of events that happen must be finite.

(ii) Now suppose that the events $E_n$ are independent, and

$$
\sum_{n=1}^{\infty} \mathbb{P}\left(E_n\right)=\infty .
$$


Then:

$$
\mathbb{P}\left(\limsup _{n \rightarrow \infty} E_n\right)=1,
$$

i.e., with probability 1 , infinitely many of the events happen.
If the events are independent, and there is "enough probability mass" overall (the sum diverges), then the system cannot avoid having infinitely many hits. 

## Exercises for Chapter 3

# 4 Integration

The goal of this Chapter is a rigorous construction of an integration functional that generalizes the idea of the Riemann integral from calculus. We will show how to "build up" towards an integration functional from *simple functions*, proving some of their key properties and how to extend these ideas to functions that can be expressed as combinations of simple functions. This will help us to develop the Expectation operator, unifying the idea of discrete and continuous random variables and their Expectations in the process. This will also help us compute expectations that are, at first glance, hard to pin down, such as for mixed random variables. 

## 4.1 Integration of Simple Functions
Recall how in the case of the Riemann integral one approximates the "area under the curve" by calculating the upper and lower rectangle sums. In the case they coincide we say that the integral is well defined. It is natural to define the integral of a multiple of an indicator function as 
	$a \cdot \mathbf{1}_E$ as $a \cdot \mu(E)$, for $E \in \Sigma$.
We can use this idea to define the class of *simple functions*:
### 4.1 Definition of Simple Functions
A function $f: S \rightarrow[0, \infty)$ is called a nonnegative simple function, if it has a representation as a finite sum: 
	$f=\sum_{i=1}^n a_i \mathbf{1}_{A_i}$
where $a_i \in[0, \infty)$ and $A_i \in \Sigma$. Basically, if we are able to split the function into a countable number of constant parts, the sum of the respective multiples of the indicator functions is what we refer to as a *simple function*. We denote the class of all nonnegative simple functions by $\mathfrak{S}^{+}$.
We directly see that simple functions, as linear combination of indicator functions, are **measurable**.

Since we remember that Riemann integrals are linear operators and are equipped with the definition of the integral for an indicator function we can directly define an integral for any $f \in \mathfrak{S}^{+}$.

### Definition 4.2: The Lebesgue Integral for Simple Functions
Let $f \in \mathfrak{S}^{+}$. The (Lebesgue) integral of $f$ with respect to the measure $\mu$ is defined as: 
	$\int f \mathrm{~d} \mu:=\sum_{i=1}^n a_i \mu\left(A_i\right)$,
When $f$ has a representation as defined in 4.1.
We see that the integral functional is nothing but a sum of set functions over the respective preimages, namely the sizes $\mu\left(A_i\right)$ of every preimage mapping to the corresponding image $a_i$.
Other common notations that are often used for this integral are $\int f(s) \mu(\mathrm{d} s)$ and $\mu(f)$.
Note that if $f=\mathbf{1}_A$, then $\mu(f)=\mu\left(\mathbf{1}_A\right)=\mu(A)$, so there is a bit of ambiguity in the notation.
Note that $\mu(f) \in[0, \infty]$ and also that the above summation is well defined, since all quantities involved are nonnegative, although possibly infinite. 

It should be clear that this definition of integral is, at first sight, troublesome. The representation of a simple function is not unique, and one might wonder if the integral defined as such may take on different values for different representations. This would be bad, but fortunately it is not the case.

### Proposition 4.3: Representation Invariance for the Lebesgue Integral
Let $f$ be a nonnegative simple function. Then the value of the integral $\mu(f)$ is independent of the chosen representation. 

**Proof**: We want to show that for any possible representations of $f$:
	$f=\sum_{i=1}^n a_i \mathbf{1}_{A_i}=\sum_{j=1}^m b_j \mathbf{1}_{B_j}$
The value of the integral remains the same, no matter which representation we pick. 
We want to show: 
	$\sum_{i=1}^n a_i \mu\left(A_i\right)=\sum_{j=1}^m b_j \mu\left(B_j\right)$
Where $A_i$ 's and $B_j$ 's form measurable sets and $A_i$ are pairwise disjoint and $a_i$ nonzero, and $B_j$ are pairwise disjoint and $b_j$ nonzero.
Step 1: Construct a common refinement:
Consider the collection of all pairwise intersections $C_{i j}=A_i \cap B_j$. Then the set of all $C_{ij}$ forms a measurable partition of $\Omega$, where some of them may possibly be empty sets. 
If now any $x \in B_k$ then $x$ must be contained in one of the $A_j$ because otherwise their respective indicator functions would be zero, contradicting the definition for our representations. 
Therefore $B_j \subset \cup A_i$  such that $\mu(B_j)$ is finite for all k and therefore our representation $B_j$ is integrable.
By the same reasoning we obtain:
	$B_k=\cup_j\left(A_j \cap B_k\right)$ and $A_j=\cup_k\left(B_k \cap A_j\right)$
If $\boldsymbol{A}_j \cap \boldsymbol{B}_k$ is not empty, then for any $x \in A_j \cap B_k$ we have
	$a_j=s_A(x)=s_B(x)=b_k$
Combining this and swapping the order of summation we get the following: 
$$
\int s_B(x) d x=\sum_{k=1}^m b_k m\left(B_k\right)=\sum_{k=1}^m b_k m\left(\bigcup_{j=1}^n A_j \cap B_k\right)=
$$
$$
=\sum_{k=1}^m b_k \sum_{j=1}^n m\left(A_j \cap B_k\right)=\sum_{j=1}^n \sum_{k=1}^m b_k m\left(A_j \cap B_k\right)=
$$
$$
=\sum_{j=1}^n \sum_{k=1}^m a_j m\left(A_j \cap B_k\right)=\sum_{j=1}^n a_j \sum_{k=1}^m m\left(A_j \cap B_k\right)=
$$
$$
=\sum_{j=1}^n a_j m\left(A_j\right)=\int s_A(x) d x
$$
This concludes the proof that the integrals agree regardless of the chosen representation. 
It remains to be shown that the integral of a simple function agrees with the integral over the canonical representation of that function, i.e. when the sets are disjoint and coefficients are nonzero. 
For this step we get back to our sets $C_i$:
Recall that any simple function $f$ can be written in its canonical form:
	$f=\sum_{i=1}^n c_i \mathbf{1}_{C_i}$
Where $C_i$ are disjoint measurable sets, $c_i$ are distinct, nonzero values that $f$ takes, and the sets are chosen such that $C_i=\left\{x \in \Omega: f(x)=c_i\right\}$. This canonical form is unique up to $\mu$-nullsets.
We observe that any representation can be refined into this canonical representation by considering: 
	$C_i=\left\{x \in \Omega: f(x)=c_i\right\}=\bigcup_{j: a_j=c_i} A_j$
Using the first part of our proof we then obtain:
$$
\sum_j a_j \mu\left(A_j\right)=\sum_{i=1}^n c_i \sum_{j: a_j=c_i} \mu\left(A_j\right)=\sum_{i=1}^n c_i \mu\left(\bigcup_{j: a_j=c_i} A_j\right)=\sum_{i=1}^n c_i \mu\left(C_i\right)
$$
Analogous to our the previous steps. Thus we have shown that the Lebesgue integral for simple functions is invariant of the chosen representation, concluding the proof. $\quad\square$

This is technically all we need to define an integration functional for discrete random variables, since we already know that random variables only take at most countably many values: 
Define $A_i=\left\{\omega \in \Omega: X(\omega)=x_i\right\}$, then $X(\omega)=\sum_i x_i \mathbf{1}_{A_i}(\omega)$, which leads us to the integral: 
	$\int X d \mathbb{P}=\sum_i x_i \mathbb{P}\left(A_i\right)$
Which is precisely the definition of the Lebesgue Integral of a simple function. For the continuous case we do need to expand our toolbox a bit more however.

### Example 4.6: Lebesgue Integrable Function that is not Riemann integrable
Let $(S, \Sigma, \mu)=([0,1], \mathcal{B}([0,1]), \lambda)$ where $f$ is the indicator function of the rational numbers in $[0, 1]$:
$f=\mathbf{1}_{\mathbb{Q} \cap[0,1]}$. We know that $\lambda(\mathbb{Q} \cap[0,1])=0$ and thus it follows that $\lambda(f)=0$. This is a nice example of a function that is not Riemann integrable, since the upper and lower limits would not converge to the same number, whereas it is Lebesgue integrable trivially and has a very sensible solution. 
Refresher: Why is $\lambda(\mathbb{Q} \cap[0,1])=0$ ? 
Two arguments: 
- The rational numbers are countable, and the measure is countably additive / $\sigma$-additive, meaning that, because the measure of singleton sets is zero, the total measure of all rationals in the interval must also be zero. 
- Given any $\varepsilon>0$, for each rational $q_i \in[0,1]$, we construct an open interval $I_i$ centered at $q_i$ of length $\ell\left(I_i\right)=\varepsilon / 2^i$. The total length of the cover is therefore $\sum_{i=1}^{\infty} \frac{\varepsilon}{2^i}=\varepsilon$. Since $\varepsilon>0$ is arbitrarily small, the Lebesgue outer measure of $\mathbb{Q} \cap[0,1]$ must therefore be arbitrarily small and thus $\lambda(\mathbb{Q} \cap[0,1])=0$.

### Proposition 4.7: Properties of Simple Functions
We say that a property of elements of S holds almost everywhere, if the set for which this property does not hold, has measure zero. For instance we say that two measurable functions are equal almost everywhere if $\mu(\{f \neq g\})=0$. Elementary properties of the integral are listed below:
Let $f, g \in \mathfrak{S}^{+}$and $c \in[0, \infty)$.
	(i) If $f \leq g$ a.e., then $\mu(f) \leq \mu(g)$.
	(ii) If $f=g$ a.e., then $\mu(f)=\mu(g)$.
	(iii) $\mu(f+g)=\mu(f)+\mu(g)$ and $\mu(c f)=c \mu(f)$.

We omit the proofs here, as they can be done by constructing measurable partitions and summing up carefully. 
## 4.2 A General definition of the Integral
How can we extend the ideas in the previous section to a more general class of functions? A direct approach is to expand definition 4.1 with the supremum, which allows us to recover all previous results in the case of simple functions, but also leads to many more powerful results.

### Definition 4.8 Integrals for Nonnegative Measurable Functions

Let $f$ be a nonnegative *measurable* function. The integral of $f$ is defined as:
$$
\mu(f):=\sup \left\{\mu(h): h \leq f, h \in \mathfrak{S}^{+}\right\},
$$
where $\mu(h)$ follows definition 4.2. As introduced above, this recovers the integral for simple functions completely.

### Proposition 4.9: Extending Integral Results to Measurable Functions
Let $f, g \in \Sigma^{+}$. If $f=0$ a.e., then $\mu(f)=0$. If $f \leq g$ a.e., then $\mu(f) \leq \mu(g)$, and if $f=g$ a.e., then $\mu(f)=\mu(g)$. 
**Proof**:
Part 1: Let $f \in \Sigma^+$, $f = 0 a.e.$ Then, using Proposition 4.7, we can take any Take $h \in \mathfrak{S}^{+}$with $h \leq f$, conforming to our supremum definition of $\mu(f)$, and obtain $\{h>0\} \subset\{f>0\}$, and thus $\mu(\{h>0\}) \leq \mu(\{f>0\})$. The right side of this inequality is zero since f is only nonzero on $\mu$-nullsets and hence $h=0$ a.e. By 4.7(ii) $\mu(h) = 0$ and therefore $\mu(f)$, being the supremum of those $\mu(h)$, must also be zero. 
Part 2: 
Let $f, g \in \Sigma^{+}$and $N=\{f>g\}$. Take $h \in \mathfrak{S}^{+}$with $h \leq f$.
Then we know that $h \mathbf{1}_N, h \mathbf{1}_{N^c} \in \mathfrak{S}^{+}$ and by proposition 4.7 (iii), and the fact that $h \mathbf{1}_N=0$ a.e., we have $\mu(h)=\mu\left(h \mathbf{1}_N\right)+\mu\left(h \mathbf{1}_{N^c}\right)=\mu\left(h \mathbf{1}_{N^c}\right)$. (We can always split a measurable function into the parts that are $\mu$-measurable and the "remaining" $\mu$-nullsets.) Moreover we see that:
	$h 1_{N^c} \leq f 1_{N^c} \leq g 1_{N^c} \leq g$
Because we have defined $\mu$ as supremum we obtain $\mu(h) \leq \mu(g)$.
By taking the supremum in this inequality over all $h$, we get $\mu(f) \leq \mu(g)$. The equality assertion follows analoguously.

### Lemma 4.11: The Zero Lemma for NN-Measurable Functions
Let $f \in \Sigma^{+}$and suppose that $\mu(f)=0$. Then $f=0$ a.e.

This already makes intuitive sense since all possible contributions to the integral can only be null or positive, since $f$ is a nonnegative measurable function. If there were any positive contribution however, we would not be able to "decrease" the total integral to zero anymore. Thus all $\mu$-measurable contributions to the integral must be zero e.g. the $f$ must be equal to 0 almost everywhere. Here is a rigorous proof to back up this intuition: 

**Proof**:
Because $\mu(f)=0$, it holds that $\mu(h)=0$ for all nonnegative simple functions with $h \leq f$.
Take $h_n=\frac{1}{n} 1_{\{f \geq 1 / n\}}$, then $h_n \in \mathfrak{S}^{+}$and $h_n \leq f$.
The equality $\mu\left(h_n\right)=0$ implies $\mu(\{f \geq 1 / n\})=0$. The desired result follows then from $\{f>0\}=\cup_n\{f \geq 1 / n\}$ and [[Measure Theoretic Probability#Corrolary 1.8 $ sigma$-sub-Additivity]].
The idea is to show that any measurable set where $f$ is at least some positive amount 1/n must have measure zero. We do this by defining our $h_n$ strictly less than or equal to $f$ and can use monotonicity of the integral to show that the resulting integral must be less than or equal to zero. 
We then use the countable union property to conclude that f must indeed be zero almost everyhwere.

### 4.12 Monotone Convergence Theorem
Let $\left(f_n\right)$ be a sequence in $\Sigma^{+}$, such that $f_{n+1} \geq f_n$ a.e. for each $n$. Let $f=\limsup f_n$. Then $\mu\left(f_n\right) \uparrow \mu(f) \leq \infty$.

This is so useful because it allows us to swap limits and integration under some rather general conditions.  
We skip the proof here as it is provided in the source material, and go directly to an application of MCT

### 4.13 Application of MCT (Canonical Simple Approximation)
Let $f \in \Sigma^{+}$ and, for each 
$n \in \mathbb{N}$, put $E_{n, i}=\left\{i 2^{-n} \leq f<(i+1) 2^{-n}\right\}\left(i \in I_n:=\left\{0, \ldots, n 2^n-1\right\}\right)$.
Put also $E_n=\{f \geq n\}$ and note that the sets $E_{n, i}$ and $E_n$ are in $\Sigma$.
Define now
	$f_n=\sum_{i \in I_n} i 2^{-n} \mathbf{1}_{E_{n, i}}+n \mathbf{1}_{E_n}$.
These $f_n$ form an increasing sequence in $\Sigma^+$, even in $\mathfrak{S}^{+}$, with limit $f$.
We have thus constructed a general sequence of simple functions with limit $f$, that can be used to approximate $\mu(f)$.

### Proposition 4.14: Linearity of the Integral for NN-measurable Functions
Let $f, g \in \Sigma^{+}$and $\alpha, \beta>0$. Then $\mu(\alpha f+\beta g)=\alpha \mu(f)+$ $\beta \mu(g) \leq \infty$.


### 4.15 Fatous Lemma
The Basic Idea behind the MCT, Fatou's Lemma, and the Dominated Convergence Theorem is that given a sequence of functions $f_n$ that converge pointwise to some limit function $f$, it is *not always* true that 
$\int \lim _{n \rightarrow \infty} f_n=\lim _{n \rightarrow \infty} \int f_n$
Fatou's Lemma, MCT, and DCT all answer the question "When do $\lim _{n \rightarrow \infty}$ and $\int$ commute?"
The MCT and DCT tell us that as long as we place certain restrictions on both $f_n$ and $f$, then we can interchange the limit and integral signs. Fatou's Lemma is a result that tells us the best we can do if we *do not* place any restrictions on the behavior of the functions. 

**Fatou's Lemma**: Let $(X, \Sigma, \mu)$ be a measurable space and $\left\{f_n: X \rightarrow[0, \infty]\right\}$ a sequence of nonnegative, measurable functions. Then the function $\liminf _{n \rightarrow \infty} f_n$ is measurable and 
$$
\int_X \liminf _{n \rightarrow \infty} f_n d \mu \leq \liminf _{n \rightarrow \infty} \int_X f_n d \mu
$$
**Proof**:
For each $k \in \mathbb{N}$, let $g_k=\inf _{n \geq k} f_n$ and define 
$$
h=\lim _{k \rightarrow \infty} g_k=\lim _{k \rightarrow \infty} \inf _{n \geq k} f_n=\liminf _{n \rightarrow \infty} f_n
$$
From the definition of the infimum we observe that $\int g_k \leq \int f_n$ for all $n \geq k$. Hence $\int \inf _{n \geq k} f_n \leq \int f_n$ for all $n \geq k$ as claimed. This allows us to write
$$
\int g_k \leq \inf _{n \geq k} \int f_n.
$$
We then observe that $g_k$ is an increasing sequence (because the infimum cannot get smaller by removing sequence elements) and $\lim _{k \rightarrow \infty} g_k=h$ pointwise. 
Applying the MCT like so: 
$$
\int \liminf _{n \rightarrow \infty} f_n= \int h=\lim _{k \rightarrow \infty} \int g_k \leq \lim _{k \rightarrow \infty} \inf _{n \geq k} \int f_n=\liminf _{n \rightarrow \infty} \int f_n
$$
where the inequality in the middle follows from (1). We arrive at the desired result. 
We conclude the proof by noting that $\liminf f_n$ is measurable as we've already shown. $\quad \square$ 

**Example from Rudin:** 
Define 
$$
f_n= \begin{cases}\mathbf{1}_{(1,2]} & \text { if } n \text { is even } \\ \mathbf{1}_{[0,1]} & \text { if } n \text { is odd }\end{cases}
$$
As n increases the graph of $f_n$ switches back and forth from the indicator over each interval.
For any given $n$, we obtain the same integral
$$
\int_{[0,2]} f_n=1
$$
But $\liminf _n f_n=0$, because $\liminf _n f_n$ is the infimum over all subsequential limits of $f_n$. This directly leads us to
$$
0=\int_{[0,2]} \liminf _{n \rightarrow \infty} f_n<\liminf _{n \rightarrow \infty} \int_{[0,2]} f_n=1,
$$
proving that a strict inequality in Fatou's lemma is possible.
Can we extend this notion of integral to (almost) arbitrary measurable functions? 

### Definition 4.16: Positive and Negative Parts of Functions

Let $f \in \Sigma$. For (extended) real numbers $x$ we define $x^{+}=\max \{x, 0\}$ and $x^{+}=\max \{x, 0\}$.
For $f: S \rightarrow[-\infty, \infty]$, we define the functions $f^{+}$ and $f^{-}$ by $f^{+}(s)=f(s)^{+}$and $f^{-}(s)=f(s)^{-}$.
This allows us to decompose any nonnegative measurable function into two parts like so: 
	$f=f^{+}-f^{-}$
Why is this relevant? Because we immediately see from this that both the positive and negative part of our initial *arbitrary* function fall into the class of *nonnegative* measurable functions again.
	If $f \in \Sigma$, then $f^{+}, f^{-} \in \Sigma^{+}$.
With this trick we can thus extend the integral properties we've derived for nonnegative measurable functions to arbitrary measurable functions:

Let $f \in \Sigma$ and assume that $\mu\left(f^{+}\right)<\infty$ or $\mu\left(f^{-}\right)<\infty$. Then we define $\mu(f):=\mu\left(f^{+}\right)-\mu\left(f^{-}\right)$.
If both $\mu\left(f^{+}\right)<\infty$ and $\mu\left(f^{-}\right)<\infty$, we say that $f$ is *integrable*.
The set of all integrable functions is denoted by $\mathcal{L}^1(S, \Sigma, \mu)$.
Note that $f \in \mathcal{L}^1(S, \Sigma, \mu)$ implies that $|f|<\infty \mu$-a.e.

### Proposition 4.18: Properties of the Integral
(i) Let $f, g \in \mathcal{L}^1(S, \Sigma, \mu)$ and $\alpha, \beta \in \mathbb{R}$. Then $\alpha f+\beta g \in \mathcal{L}^1(S, \Sigma, \mu)$ and $\mu(\alpha f+\beta g)=\alpha \mu(f)+\beta \mu(g)$. Hence $\mu$ can be seen as a linear operator on $\mathcal{L}^1(S, \Sigma, \mu)$.
(ii) If $f, g \in \mathcal{L}^1(S, \Sigma, \mu)$ and $f \leq g$ a.e., then $\mu(f) \leq \mu(g)$.
(iii) Triangle inequality: If $f \in \mathcal{L}^1(S, \Sigma, \mu)$, then $|\mu(f)| \leq \mu(|f|)$.

Proof: Exercise 4.3

This concludes the "Standard Machinery" of integration theory, whereby one often proves results by starting out with indicator functions, extending by linearity to nonnegative simple functions. After this one invokes the MCT, extending results to the class of nonnegative measurable functions. Now one shows the results to be true for functions in $\mathcal{L}^1(S, \Sigma, \mu)$ by splitting arbitrary measurable functions into positive and negative parts. This is also known as measure theoretic induction.

We will now conclude this section by the aforementioned Dominated Convergence Theorem.

### Theorem 4.19: Dominated Convergence Theorem
Let $\left(f_n\right) \subset \Sigma$ and $f \in \Sigma$. Assume that $f_n(s) \rightarrow f(s)$ for all $s$ outside of a set of measure zero. Assume also that there exists a function $g \in \Sigma^+$ such that $sup_{n}|f_{n}| \leq g$ a.e. and that $\mu(g) < \infty$. Then $\mu(|f_n - f |) \rightarrow 0$, and hence $\mu(f_n) \rightarrow \mu(f)$.

Intuition: We already know from the counter example in Fatou's lemma, that given a sequence of functions $f_n$ it is not always true that $\int \lim _{n \rightarrow \infty} f_n=\lim _{n \rightarrow \infty} \int f_n$.
Again, Fatou's lemma makes no assumptions about the nature of the functions, leading to the "here is the best you can do" interpretation we discussed above. DCT now (similar to MCT) tells us, that *if* we do place certain restrictions on the $f_n$ and $f$, then ew can interchange the limit and integral operations.
DCT: If $f_n$ is a sequence of measurable functions that converges pointwise almost everywhere to $f$, and there exists an integrable function $g$ such that $|f_n(x)| \leq g(x)$ for all $n$ and for all $x$, then $f$ is integrable and $\int_{\mathbb{R}} f=\lim _{n \rightarrow \infty} \int_{\mathbb{R}} f_n$.

Why is domination necessary?
Counter example from Kolmogorov: Define $f_n$ as 
$$
f_n(x)=n*1_{(0,1 / n]}(x)= \begin{cases}n, & \text { if } 0<x \leq \frac{1}{n} \\ 0, & \text { else }\end{cases}
$$
Clearly, this function converges pointwise to the zero function as n grows arbitrarily large -- but it is also not dominated by any $g$ since we can always find an $n$ such that $f_n$ is larger than any constant function $g$. Yet, the integral of this function always yields 1 for every $n$. The limit and integral do *not* commute in this example. 
$$
1=\lim _{n \rightarrow \infty} \int_0^1 f_n(x) d x \quad \neq \quad \int_0^1 \lim _{n \rightarrow \infty} f_n(x) d x=0
$$
Example: Application of the DCT
Compute the following Integral: 
$$
\lim _{n \rightarrow \infty} \int_{\mathbb{R}} \frac{n \sin (x / n)}{x\left(x^2+1\right)} d x
$$
We know that the composition of measurable functions is measurable, therefore the each $f_n$ in the sequence 
$$
f_n(x)=\frac{n \sin (x / n)}{x\left(x^2+1\right)} \quad \text { for each } n \in \mathbb{N} .
$$
is measurable. Now we can show, by pulling out $\frac{1}{1+x^2}$ and dividing by n, that the sequence of functions converges: 
$$
\lim _{n \rightarrow \infty} f_n(x)=\lim _{n \rightarrow \infty}\left(\frac{\sin (x / n)}{x / n}\right) \frac{1}{1+x^2} = \frac{1}{1+x^2}
$$
Because
$$
\lim _{n \rightarrow \infty} \frac{\sin (x / n)}{x / n}=1
$$
since after we change variables like so $y=\frac{x}{n} \Rightarrow n \rightarrow \infty \Longleftrightarrow y \rightarrow 0$
We obtain $\lim _{y \rightarrow 0} \frac{\sin y}{y}=1$. (Standard result for l'Hopital's rule.)
But we also see that $g(x)=\frac{1}{1+x^2}$ works as a dominating function since the sin term is always less than or equal to 1. Thus we can apply DCT and calculate the result: 
$$
\begin{aligned}
\lim _{n \rightarrow \infty} \int_{\mathbb{R}} \frac{n \sin (x / n)}{x\left(x^2+1\right)} d x & =\lim _{n \rightarrow \infty} \int_{-\infty}^{\infty} \frac{n \sin (x / n)}{x\left(x^2+1\right)} d x \\
& =\int_{-\infty}^{\infty} \frac{1}{1+x^2} d x \\
& =\left.\tan ^{-1}(x)\right|_{-\infty} ^{\infty} \\
& =\pi
\end{aligned}
$$
The proof of DCT is omitted here with a reference for the short version presented in the book. The partial result $\mu\left(\left|f_n-f\right|\right) \rightarrow 0$ is often denoted by $f_n \xrightarrow{\mathcal{L}^1} f$.

### Lemma 4.20: Scheffé's Lemma
Let $\left(f_n\right) \subset \Sigma^{+}$and assume that $f_n \rightarrow f$ a.e. Assume that $\mu\left(f_n\right)$ is finite for all $n$ and $\mu(f)<\infty$ as well. Then $\mu\left(\left|f_n-f\right|\right) \rightarrow 0$ iff $\mu\left(f_n\right) \rightarrow \mu(f)$.

## 4.3 Integrals over Subsets
This section is in a sense a prelude to the theorem of Radon-Nikodym. Let $f \in \Sigma^{+} \text {and } E \in \Sigma \text {. }$ Then we may define:
$$
\int_E f \mathrm{~d} \mu:=\mu\left(\mathbf{1}_E f\right)
$$
An alternative approach is to look at the *measurable* space $\left(E, \Sigma_E\right)$, where $\Sigma_E=\{E \cap F: F \in \Sigma\}$. Denote the restriction of $\mu$ to $\Sigma_E$ by $\mu_E$. Then $(E, \Sigma_E, \mu_E)$ is a measurable space. We consider integration on this space. 

### Proposition 4.22
Let $f\in\Sigma$ and denote by $f_E$ its restriction to $E$. Then $f_E \in \mathcal{L}^1\left(E, \Sigma_E, \mu_E\right)$ iff $1_E f \in \mathcal{L}^1(S, \Sigma, \mu)$, in which case the identity $\mu_E(f_E) = \mu(1_Ef)$ holds.
**Proof**:
First we establish that The trace sigma algebra $\Sigma_E$ is indeed a $\sigma$-Algebra:
Closure under intersections gets us the first property of $\sigma$-Algebras for free.
We then prove that for any set $X$ the trace $\sigma$-Algebra is closed under differences.
And then use the fact that Intersection Distributes over Union https://proofwiki.org/wiki/Intersection_Distributes_over_Union and know that $\Sigma_E$ is indeed a valid $\sigma$-Algebra.
The key point is now that we are working with restrictions, and on the set $E$ the function behaves identically to the unrestricted version: 
$$
\int_E f_E d \mu_E:=\int_E f d \mu=\int_S 1_E f d \mu
$$
because $\mu_E(A)=\mu(A)$ for all $A \subset E$.
Integrability of the indicator of f over the entire space also gets us integrability on the subspace:
$$
\int_E|f| d \mu=\int_S\left|1_E f\right| d \mu<\infty
$$


### Refresher: The space $\mathcal{L}^1\left(E, \Sigma_E, \mu_E\right)$
The space $\mathcal{L}^1\left(E, \Sigma_E, \mu_E\right)$ is Lebesgue space / L1 space of all functions that are defined almost everywhere on $E$ (up to sets of measure zero with respect to $\mu_E$) and with a finite absolute integral:
	$\int_E|f| d \mu<\infty$
So, practically speaking, elements of $\mathcal{L^1}$ over the real line are functions that satisfy:
	$\int_{-\infty}^{\infty}|f(x)| d x<\infty$
We also directly find some counterexamples like $|sin(x)|$ which do not have a finite integral over the real line. So in some sense, $\mathcal{L^1}$ functions have to decay to $0$ at $\pm \infty$.
One way to think about $\mathcal{L^1}$ is that it is the completion of the set of all continuous functions supported on a compact set, under the metric induced by integration. (With slight caveats.)
This is useful since we can thus approximate every $\mathcal{L^1}$ function by a sequence of continuous compactly supported functions arbitrarily closely in $L^1$-norm.
(The approximating functions are not equal pointwise (even almost everywhere), only in norm.)

Let now $f \in \Sigma^{+}$. Define for all $E \in \Sigma$
$$
\nu(E)=\int_E f \mathrm{~d} \mu\left(=\mu\left(\mathbf{1}_E f\right)\right)
$$
We can verify (exercise 4.9) that $\nu$ is a measure on $(S, \Sigma)$. We want to compute $\nu(h)$ for $h\in\Sigma^+$.
For measurable indicator functions we have by definition that the integral $\nu\left(\mathbf{1}_E\right)$ equals $\nu(E)$, which is equal to $\mu\left(\mathbf{1}_E f\right)$. More generally we have
### Proposition 4.23
Let $f \in \Sigma^{+}$and $h \in \Sigma$. Then $h \in \mathcal{L}^1(S, \Sigma, \nu)$ iff $hf \in \mathcal{L}^1(S, \Sigma, \mu)$, in which case one has $\nu(h)=\mu(h f)$.

So in essence the set function $\nu: \Sigma \rightarrow[0, \infty]$ defines a new measure over the same $\sigma$-Algebra $\Sigma$ that is absolutely continuous with respect to $\mu$ meaning $\nu \ll \mu$ because if $\mu(E)=0$, then $\nu(E)=\int_E f d \mu=0$.
So we can think of the function $f$ as a *density* that translates integration from one measure to another. $\nu(E)=\int_E f d \mu$, then integrating any $h$ with respect to $\nu$ should be equivalent to integrating $hf$ with respect to $\mu$ since $\nu$ is defined via the relationship: 
	$f=\frac{d \nu}{d \mu}$
Which is basically the Radon-Nikodym derivative.
### Example 4.24
Let $(S, \Sigma, \mu)=(\mathbb{R}, \mathcal{B}, \lambda), f \geq 0$, Borel measurable, $\nu(E)=$ $\int \mathbf{1}_E f \mathrm{~d} \lambda$ and $h f \in \mathcal{L}^1(\mathbb{R}, \mathcal{B}, \lambda)$. Then
$$
\nu(h)=\int_{-\infty}^{\infty} h(x) f(x) \mathrm{d} x
$$

## 4.4 Expectation and Integral

The main reason why we introduce integration theory in such detail, is that the Expectation of a random variable is precisely a Lebesgue integral. Indeed, consider a probability space $(\Omega, \mathcal{F}, \mathbb{P})$, and let $X$ be a real random variable defined on it. Recall that $X: \Omega \rightarrow \mathbb{R}$ is by definition a measurable function. Just by adjusting our notation from $(S, \Sigma, \mu)$ to $(\Omega, \mathcal{F}, \mathbb{P})$, we obtain the following notation for the integral of $X$ with respect to $\mathbb{P}$:
$$
\mathbb{P}(X)=\int_{\Omega} X \mathrm{~d} \mathbb{P}
$$
This holds as long as the integral is well defined, which is certainly the case if $\mathbb{P}(|X|)<\infty$. Other often used notations for this integral are $\mathbb{P} X$ and $\mathbb{E} X$.
The latter is the standard in statistics and one speaks of the $\mathbb{E}$xpectation of $X$.
Note that $\mathbb{E} X$ is always defined when $X \geq 0$ *almost surely*. The latter concept meaning almost everywhere with respect to the probability measure $\mathbb{P}$.

Further, if $h: \mathbb{R} \rightarrow \mathbb{R}$ is Borel measurable, then $Y:=h \circ X($ we also write $Y=h(X))$ is a random variable as well. We have two methods for calculating $\mathbb{E}Y$:
Exploiting the linearity of the expectation functional:
$$
\mathbb{E} Y=\int_{\Omega} Y \mathrm{~d} \mathbb{P}=\int_{\Omega} h(X) \mathrm{d} \mathbb{P},
$$
and using the following proposition, that allows us to compute  $\mathbb{E}Y$ as:
$$
\mathbb{E} Y=\int_{\mathbb{R}} y \mathbb{P}^Y(\mathrm{~d} y)=\int_{\mathbb{R}} h(x) \mathbb{P}^X(\mathrm{~d} x) .
$$
### Proposition 4.27 Pushforward 1
Let $X$ be a random variable, and $h: \mathbb{R} \rightarrow \mathbb{R}$ Borel measurable. Let $\mathbb{P}^X$ be the distribution of $X$. Then $h \circ X \in \mathcal{L}^1(\Omega, \mathcal{F}, \mathbb{P})$ iff $h \in \mathcal{L}^1\left(\mathbb{R}, \mathcal{B}, \mathbb{P}^X\right)$, in which case
$$
\mathbb{E} h(X)=\int_{\mathbb{R}} h \mathrm{dP}^X .
$$
**Proof:** Exercise 4.11
Remark: Proposition 4.27 is defined in terms of equality of two integrals defined on different probability spaces. There is nothing essential here in working with probability measures. Indeed, consider a more general set up, where we have a measure space $(S, \Sigma, \mu)$ and another measurable space $\left(S^{\prime}, \Sigma^{\prime}\right)$. Let $f: S \rightarrow S^{\prime}$ be a measurable mapping and $\left(S^{\prime}, \Sigma^{\prime}\right)$. Let $f: S \rightarrow S^{\prime}$ and $h: S^{\prime} \rightarrow \mathbb{R}$ be Borel-measurable, then the composition $h(f)=h \circ f: S \rightarrow \mathbb{R}$ is Borel-measurable. Moreover, we can define th emeasure $\mu^f$ (also called push-forward measure) on $\Sigma^{\prime}$ by:
$$\mu^f\left(E^{\prime}\right):=\mu\left(f^{-1}\left(E^{\prime}\right)\right), E^{\prime} \in \Sigma^{\prime} .$$
Then $h \circ f \in \mathcal{L}^1(S, \Sigma, \mu)$ iff $h \in\left(S^{\prime}, \Sigma^{\prime}, \mu^f\right)$, in which case 
$$
\int_S h(f) \mathrm{d} \mu=\int_{S^{\prime}} h \mathrm{~d} \mu^f
$$
Note that the distribution of a random variable is a push-forward measure: $\mathbb{P}^X=\mathbb{P} \circ X^{-1}$.
This is known as the transformation formula for expectations, and in general the transformation formula for integrals of arbitrary measure. 

We thus conclude that the definition of expectation as a Lebesgue integral with respect to a probability measure yields the familiar formulas -- sums for discrete random variables, and Riemann integrals for random variables with an ordinary density function -- as special cases. We see that the Lebesgue integral serves as a unifying concept for expectation. At least as important is that we can use the powerful convergence theorems (MCT, DCT, Fatou's Lemma) for expectations as well. Every real constant function has a well defined, and trivially finite, expectation. Therefore one can in pertaining cases apply the DCT with the function g equal to a constant. Here is a simple example of the application of MCT: 
### Example 4.30:
Let $\left(X_n\right)$ be a sequence of nonnegative random variables, so all $\mathbb{E} X_n \leq \infty$ are well defined. Then $\sum X_n$ is a well defined random variable as well, nonnegative, and we have $\mathbb{E}\left(\sum X_n\right)=\sum \mathbb{E} X_n$. Moreover if $\sum \mathbb{E} X_n<\infty$, then $\sum X_n<\infty$ a.s. We thus get to swap expectations and sums "for free", as long as certain mild conditions are met.
Verification of these assertions is straightforward and left as Exercise 4.12.

### 4.31: Markov, Chebychev, and Jensen Inequalities
This paragraph presents some key inequalities that are very useful for proofs in Probability Theory.

#### Markov Inequality
Let $X$ be a real valued random variable and $g: \mathbb{R} \rightarrow [0, \infty]$ an increasing function. (e.g. a distribution function). Then 
$$
\mathbb{E} g(X) \geq g(c) \mathbb{P}(X \geq c) .
$$
**Proof:** This follows from the inequality $g(X) \mathbf{1}_{\{X \geq c\}} \geq g(c) \mathbf{1}_{\{X \geq c\}}$.
The Markov Inequality alone may seem not very useful, but is a very powerful stepping stone to Chebychev's Inequality.

#### Chebychev Inequality
An example of the Markov Inequality is obtained by taking $g(x) = x^+$ and replacing $X$ with $|X|$. One gets $\mathbb{E}|X| \geq c \mathbb{P}(|X| \geq c)$. In the special case where $g(x)$ is $(x^+)^2$, it is known as Chebychev's inequality. This name is especially used, if we apply it with $|X - \mathbb{E}X|$ instead of $X$. For $c \geq 0$ we then obtain  $\operatorname{Var} X \geq c^2 \mathbb{P}(|X-\mathbb{E} X| \geq c)$.
A more general, measure theoretic statement of Chebychev's Inequality is:
$$\mu\{x: x\in A, f(x) \geq c\} \leq \frac{1}{c} \int_Af(x)d\mu$$
With a simple **proof**:
$\int_A f \geq \int_S f \geq \int_S c=c \mu(S)$ 
where $S=\{x \in A \mid f(x) \geq \lambda\}$.
In essence this says that, since the integral over our set S must be at least the measure of S times the constant function c, we can rearrange to get the final inequality.
Thus, since in a probabilistic sense the right side of the inequality is nothing but the Expectation, we can interpret this as "the probability that a random variable is greater than or equal to c is less than or equal to the Expectation of the RV divided by c." So just knowing the Expectation is enough to get upper bounds for the probability of some events. Take for example: Let the expected value of gambling be a gain of $5. So we can obtain an upper bound for the probability of gaining $20 as $\frac{5}{20}$ or $0.25$. 
Probabilistic interpretation:
If you take $f=|X-\mathbb{E} X|^2$ and $c=\varepsilon^2$, you get:

$$
\mathbb{P}(|X-\mathbb{E} X| \geq \varepsilon) \leq \frac{\mathbb{E}\left(|X-\mathbb{E} X|^2\right)}{\varepsilon^2}=\frac{\operatorname{Var}(X)}{\varepsilon^2} .
$$
Which builds a nice connection to the variance of the random variable. 
#### Jensen's Inequality:
We skip some properties of convex sets and convex functions here and just state the following:
Let $g: G \rightarrow \mathbb{R}$ be convex and $X$ a random variable with $\mathbb{P}(X \in G)=1$. Assume that $\mathbb{E}|X|<\infty$ and $\mathbb{E}|g(X)|<\infty$. Then

$$
\mathbb{E} g(X) \geq g(\mathbb{E} X)
$$
The expected value of a convex transformation of a RV is at least the convex transformation of the expected value. 
We can directly use this to prove the nonnegativity of Variance: 
Recall that variance can be written as:
$$
\operatorname{Var}(X)=\mathbb{E}\left[(X-\mathbb{E} X)^2\right] .
$$
Consider the convex function $g(x)=x^2$. Then applying Jensen gives:
$$
\mathbb{E}\left[X^2\right] \geq(\mathbb{E} X)^2 .
$$
This is exactly:
$$
\mathbb{E}\left[X^2\right]-(\mathbb{E} X)^2 \geq 0 .
$$
And as a corollary we get some useful moment inequalities:
$$
\mathbb{E}\left[X^p\right] \geq(\mathbb{E} X)^p .
$$
Telling us that higher moments grow faster than powers of the expectation.
Jensen is also very useful for negative log transformations, which are very common in Maximum Likelihood, since $-log$ is convex for any positive real valued random variable.


## 4.5 Functions of Bounded Variation and Stieltjes Integrals
In this section we define functions of bounded variation and review some of their basic properties. Stieltjes integrals will be discussed subsequently. We consider functions defined on an interval $[a, b].$ Next to these we consider partitions $\Pi$ of $[a, b]$ -- finite subsets $\left\{t_0, \ldots, t_n\right\}$ of $[a, b]$ with the  convention $t_0 \leq \cdots \leq t_n$, and $\mu(\Pi)$ denotes the mesh of $\Pi$. 
$$
\mu(\Pi)=\max _{1 \leq i \leq n}\left(t_i-t_{i-1}\right) .
$$
Extended partitions, denoted $\Pi^*$, are partitions $\Pi$, coupled with additional points $\tau_i$  with $t_{i-1} \leq \tau_i \leq t_i$. By definition $\mu\left(\Pi^*\right)=\mu(\Pi)$. Given a function $\alpha$ over the partition $\Pi$, we define 
$$
V^1(\alpha ; \Pi):=\sum_{i=1}^n\left|\alpha\left(t_i\right)-\alpha\left(t_{i-1}\right)\right|,
$$
as the *variation* of $\alpha$ over the partition $\Pi$.
One again, we make use of the supremum over the collections of all possible partitions, to arrive at the definition of *functions of bounded variation*:

### 4.33 Functions of Bounded Variation
A function $\alpha$ is said to be of bounded variation if $V^1(\alpha):= \sup _{\Pi} V^1(\alpha ; \Pi)<\infty,$ where the supremum is taken over all partitions $\Pi$. The variation function $\mathcal{v}_\alpha:[a, b] \rightarrow \mathbb{R}$ is defined by 
$v_\alpha(t)=V^1\left(\alpha 1_{[a, t]}\right)$. In this way the variation function yields how much total variation has accrued between $a$ and $t$. It is monotone increasing and has values: $v_\alpha(a)=0$, and $v_\alpha(b)=V^1(\alpha)$ for the two trivial cases. 
A *refinement* $\Pi^\prime$ of a partition $\Pi$ satisfies by definition the inclusion $\Pi \subset \Pi^{\prime}$. In such a case, one has 
$\mu\left(\Pi^{\prime}\right) \leq \mu(\Pi)$ and $V^1\left(\alpha ; \Pi^{\prime}\right) \geq V^1(\alpha ; \Pi)$. It follows from the definition of $V^1(\alpha)$, that there exists a sequence $(\Pi_n)$ of partitions (taken as successive refinements) such that $V^1\left(\alpha ; \Pi_n\right) \rightarrow V^1(\alpha)$.

### Example 3.34 Variation as Riemann Sum
Let $\alpha$ be continuously differentiable and assume $\int_a^b|\alpha^\prime(t)|dt$ is finite. Then the variation of alpha is nothing but the Riemann integral of the absolute derivative of alpha: 
$$
V^1(\alpha)=\int_a^b\left|\alpha^{\prime}(t)\right| \mathrm{d} t
$$
Since we can express the variation as a Riemann sum:
$$
\sum_{i=1}^n\left|\alpha^{\prime}\left(\tau_i\right)\right|\left(t_i-t_{i-1}\right),
$$
Where the $\tau_i$ satisfy $t_{i-1} \leq \tau_i \leq t_i$ and $\alpha^{\prime}\left(\tau_i\right)=\frac{\alpha\left(t_i\right)-\alpha\left(t_{i-1}\right)}{t_i-t_{i-1}}$.
This makes intuitive sense since, by taking the supremum over finer and finer refinements we essentially approximate the absolute value of finite differences for each interval and then sum them up to obtain the total variation.
We immediately see that any monotone function $\alpha$ is of bounded variation, where we can express the variation as $|\alpha(b)-\alpha(a)|$ with $v_\alpha(t)=|\alpha(t)-\alpha(a)|$ respectively. 
The difference of two increasing functions is of bounded variation. This fact also has a converse:
### Proposition 4.35 Decomposition of Functions of Bounded Variation
Let $\alpha$ be of bounded variation. Then there exists increasing functions $v_\alpha^{+}$and $v_\alpha^{-}$ such that $v_\alpha^{+}(a)=v_\alpha^{-}(a)=0, \alpha(t)-\alpha(a)=v_\alpha^{+}(t)-v_\alpha^{-}(t)$. Moreover, one can choose them such that $v_\alpha^{+}+v_\alpha^{-}=v_\alpha$. 
This is known as the canonical decomposition theorem (due to Jordan) for functions of bounded variation of one real variable. This decomposition is related to the Jordan decomposition (of a signed measure). 

The decomposition in this proposition enjoys a minimality property. If $w^{+}$and $w_{-}$are increasing functions, $w^{+}(a)=w^{-}(a)=0$ and $\alpha(t)-\alpha(a)=w^{+}(t)-$ $w^{-}(t)$, then for all $t^{\prime}>t$ one has $w^{+}\left(t^{\prime}\right)-w^{+}(t) \geq v_\alpha^{+}\left(t^{\prime}\right)-v_\alpha^{+}(t)$ and $w^{-}\left(t^{\prime}\right)-$ $w^{-}(t) \geq v_\alpha^{-}\left(t^{\prime}\right)-v_\alpha^{-}(t)$. This property is basically the counterpart of the Jordan decomposition (6.4) of signed measures.

The following definition generalizes the concept of Riemann Integral.
### Definition 4.36 Stieltjes Integral
Let $f, \alpha:[a, b] \rightarrow \mathbb{R}$ and $\Pi^*$ be an extended partition of $[a, b]$. Write

$$
S\left(f, \alpha ; \Pi^*\right)=\sum_{i=1}^n f\left(\tau_i\right)\left(\alpha\left(t_i\right)-\alpha\left(t_{i-1}\right)\right)
$$
We say that $S(f, \alpha)=\lim _{\mu\left(\Pi^*\right) \rightarrow 0} S\left(f, a ; \Pi^*\right)$, if for all $\varepsilon>0$, there exists $\delta>0$ such that $\mu\left(\Pi^*\right)<\delta$ implies $\left|S(f, \alpha)-S\left(f, \alpha ; \Pi^*\right)\right|<\varepsilon$. If this happens, we say that $f$ is integrable w.r.t. $\alpha$ and we commonly write $\int f \mathrm{~d} \alpha$ for $S(f, \alpha)$, and call it the Stieltjes integral of $f$ w.r.t. $\alpha$.

Note the difference to traditional Riemann sums: In the Riemann Integral, the increment is the length of the interval: $\sum f\left(\tau_i\right)\left(t_i-t_{i-1}\right)$ (using the midpoints $\tau_i$ as an alternative to upper and lower sums), but in the Stieltjes integral the increment is the *increment* of $\alpha$ over the interval: $\alpha\left(t_i\right)-\alpha\left(t_{i-1}\right)$. Roughly, in the Stieltjes integral we think of $\alpha$ as providing a generalized measure of "weight" assigned to each interval, which allows us to integrate functions that have discontinuities. If $\alpha$ is continuous with continuous derivative we recover the Riemann integral. 
We effectively Integrate $f$ weighted by some *integrator* $\alpha$:

The Riemann-Stieltjes integral is effectively a Riemann integral, except the integrand is "weighted" at every point according to a given function, the "integrator." In fact, if the integrand is $f$ and the integrator $g$ is differentiable, then
$$
\int_a^b f(x) d g(x)=\int_a^b f(x) g^{\prime}(x) d x
$$
If $g$ is increasing (and when I learned about the Riemann-Stieltjes integral it was required to be), then you can think of $g$ as sort of acting on the real line - and also acting on the graph of $f$. For example, if $g(x)=2 x$, then $g$ acts on the real line by "stretching" by a factor of 2 . If you think of $f$ as being graphed on a rubber sheet (corresponding to a coordinate plane) which you stretch yourself by a factor of 2 , then the area under the graph of $f$ will double, corresponding to the fact that
$$
\int_a^b f(x) d(2 x)=2 \int_a^b f(x) d x
$$
If $g$ is a more complicated function, then the transformation might be harder to parse, but this is effectively what is happening.

### Proposition 4.37 Stieltjes Integrability Conditions
Let $f, \alpha:[a, b] \rightarrow \mathbb{R}, f$ continuous and $\alpha$ of bounded variation. Then $f$ is integrable with respect to $\alpha$. Moreover, the triangle inequality $\left|\int f \mathrm{~d} \alpha\right| \leq \int|f| \mathrm{d} v_\alpha$ holds.
Intuitively integrability w.r.t. $\alpha$ makes sense, since functions of bounded variation can be expressed, by the previous proposition, as the difference of two monotonically nondecreasing functions. We already established that measurability and integrability hold under sums and differences. We skip the rigorous $\epsilon - \delta$ proof here and refer to chapter 4 in the linked script.

### Proposition 4.38 Integration by Parts
Let $f, \alpha:[a, b] \rightarrow \mathbb{R}$, be continuous and of bounded variation. Then the following integration by parts formula holds: 
$$
\int f \mathrm{~d} \alpha+\int \alpha \mathrm{d} f=f(b) \alpha(b)-f(a) \alpha(a)
$$
The proof is compact and combines proposition 4.37 with Abel's summation formula. The proof for the formula on wikipedia applies Integration by Parts however which seems circular. More investigations are here needed.

We can use Integration by Parts to define $\int\alpha d f$ for functions of bounded variation by putting:
$$
\int \alpha \mathrm{d} f:=f(b) \alpha(b)-f(a) \alpha(a)-\int f \mathrm{~d} \alpha .
$$
### Proposition 4.40 Equality of Stieltjes and Lebesgue Integral
Let $f, \alpha:[a, b] \rightarrow \mathbb{R}, f$ continuous and $\alpha$ of bounded variation. Then the Lebesgue integral $\int f \mathrm{~d} \mu_\alpha$ and the Stieltjes integral $\int f \mathrm{~d} \alpha$ are equal, $\int f \mathrm{~d} \mu_\alpha=\int f \mathrm{~d} \alpha$.
**Proof**: Exercise 4.17
## 4.6 $\mathcal{L}^p$-Spaces of Random Variables

In this section we introduce the $p$-norms and the spaces of random variables with finite $p$-norm. We start with a definition.
### Definition 4.41 Random Variables with Finite Moments
Let $1 \leq p<\infty$ and $X$ a random variable on $(\Omega, \mathcal{F}, \mathbb{P})$. If $\mathbb{E}|X|^p<\infty$, we write $X \in \mathcal{L}^p(\Omega, \mathcal{F}, \mathbb{P})$ and $\|X\|_p=\left(\mathbb{E}|X|^p\right)^{1 / p}$.

The notation $\|\cdot\|$ suggests that we are dealing with a norm. In a sense, this is correct, but we will not rigorously prove this until the end of this section. It is however obvious that $\mathcal{L}^p:=\mathcal{L}^p(\Omega, \mathcal{F}, \mathbb{P})$ is a vector space, since $|X+Y|^p \leq(|X|+|Y|)^p \leq 2^p\left(|X|^p+\right.$ $\left.|Y|^p\right)$.
In the special case $p=2$, we have for $X, Y \in \mathcal{L}^2$ that $|X Y|=\frac{1}{2}\left((|X|+|Y|)^2-\right. \left.X^2-Y^2\right)$ has finite expectation and is thus in $L^1$. Of course we also have $|\mathbb{E}(X Y)| \leq \mathbb{E}|X Y|$, which directly leads us to the Cauchy-Schwarz inequality.
### Proposition 4.42 The Cauchy-Schwarz Inequality
Let $X, Y \in \mathcal{L}^2$. Then $X Y \in \mathcal{L}^1$ and $\mathbb{E}|X Y| \leq\|X\|_2\|Y\|_2$.
**Interpretation:** If $X, Y$ have finite variance, then their product has finite expectation and:
$$
\mathbb{E}|X Y| \leq \sqrt{\mathbb{E}\left[X^2\right]} \sqrt{\mathbb{E}\left[Y^2\right]} .
$$
**Proof** If $\mathbb{E} Y^2=0$, then $Y=0$ a.s. (Lemma 4.11), so also $X Y=0$ a.s. and there is nothing to prove. Assume then that $\mathbb{E} Y^2>0$ and let $c=\mathbb{E}|X Y| / \mathbb{E} Y^2$. One trivially has $\mathbb{E}(|X|-c|Y|)^2 \geq 0$. But the left hand side equals $\mathbb{E} X^2-$ $\frac{(\mathbb{E}|X Y|)^2}{\mathbb{E} Y^2}$.

This directly leads us to the final proposition of this section:
### Proposition 4.43 Expectation of Independent Random Variables
Let $X, Y \in \mathcal{L}^1(\Omega, \mathcal{F}, \mathbb{P})$ be independent random variables. Then $X Y \in \mathcal{L}^1(\Omega, \mathcal{F}, \mathbb{P})$ and $\mathbb{E}(X Y)=\mathbb{E} X \cdot \mathbb{E} Y$.
This can be proven by the "standard machine", we refer for this to the original script.
### Summary on Expectation:
Given any random variable $X$, the distribution measure is:
$$
\mu_X(B)=\mathbb{P}\{\omega: X(\omega) \in B\} .
$$
Then:
$$
\mathbb{E}[X]=\int_{\mathbb{R}} x d \mu_X(x)
$$
This is the Lebesgue integral with respect to the probability measure $\mu_X$.
Recall that any probability measure $\mu_X$ corresponds to the cumulative distribution function (roughly, see https://math.stackexchange.com/questions/4764604/probability-measure-as-a-synonym-of-cumulative-distribution-function-cdf for the precise correspondence):
$$
F(x)=\mathbb{P}(X \leq x) .
$$
And the integral
$$
\int_{\mathbb{R}} g(x) d F(x)
$$
is the Lebesgue-Stieltjes integral, which integrates $g$ with respect to the CDF $F$.
So in this notation:
$$
\mathbb{E}[X]=\int_{\mathbb{R}} x d F(x)
$$
This is equivalent to integrating with respect to $\mu_X$.
But we know from the Stieltjes Integral, that we can just take the derivative of the integrator to reduce to the Riemann form. This is analogous to the following:
If $\mu_X$ is absolutely continuous with respect to Lebesgue measure, there is a density $f(x)$ such that:
$$
d \mu_X(x)=f(x) d x
$$
and:
$$
F(x)=\int_{-\infty}^x f(t) d t
$$
Then:
$$
\mathbb{E}[X]=\int_{\mathbb{R}} x f(x) d x
$$
Here is a very nice visual interpretation of the Stieltjes Integral:
https://sci-hub.se/https://doi.org/10.2307/2322483
https://arxiv.org/pdf/math/0110241
https://sci-hub.se/https://doi.org/10.1080/07468342.2019.1580109
https://sci-hub.se/https://link.springer.com/article/10.1023/B:TAMP.0000018457.70786.36

Here is a complete treatise on the Stieltjes Integral with some nice applications in probability:
https://www.diva-portal.org/smash/get/diva2:719488/FULLTEXT01.pdf

# 5 Product Measures

In the preceding chapters, we introduced Measure- and Probability Spaces, Random Variables and their Expectation rigorously, but so far only for the "one dimensional" case. A natural question is "Can we directly extend these ideas to multiple, possibly dependent, Random Variables?". We can start by introducing an informal example.

Take $f: S_1 \times S_2 \rightarrow \mathbb{R}$ and assume any good notion of measurability and integrability. Then $\mu\left(f\left(\cdot, s_2\right)\right):=\int f\left(\cdot, s_2\right) \mathrm{d} \mu_1$ defines a function of $s_2$, and so we'd like to take the integral with respect to $\mu_2$. One could also have performed the integration with respect to $\mu_2$ first, leading us directly to the question whether these integrals are well defined and both approaches yield the same result. 
Readers already familiar with Fubini's theorem will know that certain conditions have to be fulfilled to be able to swap the order of integration, here is an illustrative example of when this might fail.

We know that integration with respect to the counting measure is nothing but addition. In this context what we've outlined above is just interchanging the order of summation. So if $(a_{n,m})$ is a double array of real numbers, the above can be expressed as  $\sum_n \sum_m a_{n, m}=\sum_m \sum_n a_{n, m}$, which is obviously true if $n$ and $m$ run through a finite set, but this does not necessarily hold for indices from infinite sets. Consider for example
$$
a_{n, m}=\left\{\begin{aligned}
1 & \text { if } n=m+1 \\
-1 & \text { if } m=n+1 \\
0 & \text { else. }
\end{aligned}\right.
$$
We can visualize this as a two dimensional grid of numbers with zero everywhere except the lower and upper off diagonals. In particular, we see that the lower off diagonal is filled with 1 entries, the upper diagonal is filled with negative one. We thus see that the first row of this infinite grid sums to -1, since it does not contain values of the lower off diagonal. Any other row sums to zero, since they contain both upper and lower values. Thus we find $\sum_n \sum_m a_{n, m}=-1$. Following the same logic we can show that, by summing over columns instead of rows, we get $\sum_m \sum_n a_{n, m}=+1$. 
What are sufficient conditions that allow us to interchange the order of summation? We will show that $\sum_m \sum_n\left|a_{n, m}\right|<\infty$ is such a sufficient condition. As a side remark we note that this case has everything to do with a well known theorem by Riemann that tells us that a series of real numbers is absolutely convergent iff it is unconditionally convergent. (All reorderings of the series converge to the same value.)

## 5.1 Product of Two Measure Spaces
Our goal is to construct a measure space $(S, \Sigma, \mu)$ with $S=S_1 \times S_2$. Just taking the Cartesian product of the two universes is straightforward enough, but we do need to prove that the product $\sigma$-Algebra remains a proper $\sigma$-Algebra and measurability properties still hold.
First we construct $\Sigma$. It is natural that "measurable rectangles" are in $\Sigma$. Let $\mathcal{R}$ be $\left\{E_1 \times E_2: E_1 \in \Sigma_1, E_2 \in \Sigma_2\right\}$. This is a $\pi$-System as all possible intersections of rectangles are also rectangles (or the empty set), but not necessarily a $\sigma$-Algebra since the complement of a rectangle is not a rectangle. (Consider $[0,1] \times[0,1] \cup[2,3] \times[2,3]$ or any other nontrivial example.) Therefore we define $\Sigma:=\sigma(\mathcal{R})$, the *product $\sigma$-algebra* of $\Sigma_1$ and $\Sigma_2$. A common notation for this product $\sigma$-Algebra is the standard cartesian product: $\Sigma=\Sigma_1 \times \Sigma_2$.

Alternatively, one can consider the projections $\pi_i: S \rightarrow S_i$, defined by $\pi_i\left(s_1, s_2\right)=s_i$. It is easy to show that $\Sigma$ coincides with the smallest such $\sigma$-Algebra that makes these projections measurable. 
Consider, for example the rectangle $R=[0,1] \times[2,3]$. Taking the projection $\pi_1: \mathbb{R}^2 \rightarrow \mathbb{R}$, where $\pi_1(x, y)=x$ we obtain the image $[0, 1]$ and preimage $\pi_1^{-1}([0,1])=\left\{(x, y) \in \mathbb{R}^2: x \in[0,1], y \in \mathbb{R}\right\}=[0,1] \times \mathbb{R}$.
The product $\sigma$-Algebra is the smallest $\sigma$-Algebra that contains any such vertical and horizontal strips, since this allows us, with countably many set operations, to construct any Borel-measurable subset of $\mathcal{B}(\mathbb{R}) \times \mathcal{B}(\mathbb{R}) \subseteq \mathcal{B}\left(\mathbb{R}^2\right)$.

Next to the projections, we now consider *embeddings*. For a fixed $s_1 \in S_1$ we define $e_{s_1}: S_2 \rightarrow S$ by  $e_{s_1}\left(s_2\right)=\left(s_1, s_2\right)$. Similarly, we define $e^{s_2}\left(s_1\right)=\left(s_1, s_2\right)$. One easily checks that the embeddings $e_{s_1}$ are $\Sigma_2 / \Sigma$-measurable and that the $e^{s_2}$ are $\Sigma_1 / \Sigma$-measurable. As a consequence we have the following proposition.

### Proposition 5.1
Let $f: S \rightarrow \mathbb{R}$ be $\Sigma$-measurable. Then the marginal mappings $s_1 \mapsto f\left(s_1, s_2\right)$ and $s_2 \mapsto f\left(s_1, s_2\right)$ are $\Sigma_1$-, respectively $\Sigma_2$-measurable, for any $s_2 \in S_2$, respectively $s_1 \in S_1$.

**Proof**: This follows from the fact that a composition of measurable functions is also measurable.

The converse statement of proposition 5.1 is not true in general. There are functions $f: S \rightarrow \mathbb{R}$ that are not measurable with respect to the product $\sigma$-Algebra $\Sigma$ ,although the mappings $s_1 \mapsto f\left(s_1, s_2\right)$ and $s_2 \mapsto f\left(s_1, s_2\right)$ are $\Sigma_{1^{-}},$ respectively $\Sigma_2$-measurable. Counterexamples are not obvious. Fortunately, there are also conditions that are sufficient to have measurability of $f$ with respect to $\Sigma$, when measurability of the marginal functions is given. (See Exercise 5.8).

Having constructed the product $\sigma$-algebra $\Sigma$, we now draw our attention to the construction of the product measure $\mu$ on $\Sigma$, denoted by $\mu_1 \times \mu_2$. We will construct $\mu$ such that the property $\mu\left(E_1 \times E_2\right)=\mu_1\left(E_1\right) \mu_2\left(E_2\right)$ holds. This justifies the name product measure. We will assume that the measures $\mu_1$ and $\mu_2$ are finite until further notice.

Consider a bounded $\Sigma$-measurable function $f$. We know that the mappings $s_i \mapsto f\left(s_1, s_2\right)$ are $\Sigma_i$-measurable and therefore the respective integrals $\mu_i$ are well defined. Let then
$$
\begin{aligned}
I_1^f\left(s_1\right) & =\int f\left(s_1, s_2\right) \mu_2\left(\mathrm{~d} s_2\right) \\
I_2^f\left(s_2\right) & =\int f\left(s_1, s_2\right) \mu_1\left(\mathrm{~d} s_1\right)
\end{aligned}
$$
be the respective marginal integrals. 
### Lemma 5.3 Preamble to Fubini
Let $f$ be a bounded $\Sigma$-measurable function. Then the mappings $I_i^f: S_i \rightarrow \mathbb{R}$ are $\Sigma_i$-measurable $(i=1,2)$. Moreover we have the identity
$$
\mu_1\left(I_1^f\right)=\mu_2\left(I_2^f\right)
$$
or, in a more appealing notation,
$$
\int_{S_1}\left(\int_{S_2} f\left(s_1, s_2\right) \mu_2\left(\mathrm{~d} s_2\right)\right) \mu_1\left(\mathrm{~d} s_1\right)=\int_{S_2}\left(\int_{S_1} f\left(s_1, s_2\right) \mu_1\left(\mathrm{~d} s_1\right)\right) \mu_2\left(\mathrm{~d} s_2\right) .
$$
**Proofsketch**: This can be proven by considering the space of all bounded $\Sigma$-measurable functions that satisfy the assertions of the lemma and noticing that this is indeed a vector space, since sums of measurable functions retain their measurability and integrals are linear operators. We then show that if $f_n$ is in this vector space and $f_n \geq 0$ and $f_n \uparrow f$ where $f$ is bounded then $f$ is also in our vector space. We then use the MCT to swap limits and integrals which leads us to  $\mu_1\left(I_1^{f_n}\right)=\mu_2\left(I_2^{f_n}\right)$ for all $n$, in the case where $f$ is a bounded $\Sigma$-measurable function. All that is left to show now is that $\mathcal{H}$ contains the indicators of all sets in $\mathcal{R}$ which would allow us, by [[Measure Theoretic Probability#Theorem 3.6 Monotone Class Theorem]], to conclude that $\mathcal{H}$ coincides with the space of all bounded $\Sigma$-measurable functions.

Lemma 5.3 is essentially a special case of Fubini's theorem, for bounded functions and finite product measures, without any explicit integrability assumptions just yet. We're essentially proving that slicing a measurable function and then integrating the slices yields a measurable marginal function. Moreover, the double integral is symmetric in the product measure. We then start with simple rectangles and build up using the monotone class machinery to show that the *benign* space $\mathcal{H}$ we picked to satisfy the conditions of the lemma coincides with the full space of bounded $\Sigma$-measurable functions. 

It follows directly from this, that for al $E \in \Sigma$, the indicator function $1_E$ satisfies the assertions of the lemma. This allows us to define the following:
### Definition 5.4 Product Measure
We define $\mu: \Sigma \rightarrow[0, \infty)$ by $\mu(E)=\mu_2\left(I_2^{\mathbf{1}_E}\right)$ for $E \in \Sigma$.
In Fubini's Theorem below we assert that this defines a measure on $(S, \Sigma)$ and also tells us how to compute integrals with respect to this measure in terms of iterated integrals w.r.t . $\mu_1$ and $\mu_2$.
### Theorem 5.5 Fubini's Theorem
The mapping $\mu: \Sigma \rightarrow[0, \infty)$ by $\mu(E)=\mu_2\left(I_2^{\mathbf{1}_E}\right)$ for $E \in \Sigma$ has the following properties:
	(i) It is a measure on $(S, \Sigma)$. Moreover, it is the only measure on $(S, \Sigma)$ with the property that $\mu\left(E_1 \times E_2\right)=\mu_1\left(E_1\right) \mu_1\left(E_2\right)$. It is therefore called the product measure of $\mu_1$ and $\mu_2$ and often written as $\mu_1 \times \mu_2$.
	(ii) If $f \in \Sigma^{+}$, then
$$
\mu(f)=\mu_2\left(I_2^f\right)=\mu_1\left(I_1^f\right) \leq \infty .
$$
	(iii) If $f \in \mathcal{L}^1(S, \Sigma, \mu)$, then Equation (5.3) is still valid and $\mu(f) \in \mathbb{R}$.

**Proof** (i) It is obvious that $\mu(\emptyset)=0$. If $\left(E_n\right)$ is a disjoint sequence in $\Sigma$ with union $E$, then we have $\mathbf{1}_E=\lim _n \sum_{i=1}^n \mathbf{1}_{E_i}$. Linearity of the integral and Monotone Convergence (applied two times) show that $\mu$ is $\sigma$-additive. Uniqueness of $\mu$ follows from Theorem 1.15 applied to the $\pi$-system $\mathcal{R}$.
(ii) We use the standard machine. The two equalities in (5.3) are by definition of $\mu$ valid for $f=\mathbf{1}_E$, when $E \in \Sigma$. Linearity of the integrals involved show that it is true for nonnegative simple functions $f$ and Monotone Convergence yields the assertion for $f \in \Sigma^{+}$.
(iii) Of course, here we have to use the decomposition $f=f^{+}-f^{-}$. The tricky details are left as Exercise 5.2.

Fubini has been proven under the standing assumption that the initial measures $\mu_1$ and $\mu_2$ are finite. The results extend to the case where both of these measures are $\sigma$-finite. We can see this by splitting up each of the $S_i$ into countable unions of disjoint sets and observing that the individual results still apply to the involved integrals by splitting the integration over the sets $S_{ij}$ and adding up the results. 
We note that if one goes beyond $\sigma$-finite measures the assertion may no longer be true. 

## 5.2 Applications in Probability Theory
In this section we consider real valued random variables, as well as real *random vectors*. The latter are defined as follows:
Consider a probability space $(\Omega, \mathcal{F}, \mathbb{P})$ and a map $X: \Omega \rightarrow E$, where $E$ is some other set. Let $\mathcal{E}$ be a $\sigma$-Algebra on $E$. If the map $X$ is $\mathcal{F} / \mathcal{E}$-measurable, $X$ is also called a random element of $E$. If $E$ is a vector space, we call $X$ a **Random Vector**. Notice that this definition depends on the $\sigma$-Algebras at hand, which we don't immediately recognize in the term *random vector*. 
A concrete example of such a vector space is $\mathbb{R}^2$. Suppose we have two random variables $X_1, X_2: \Omega \rightarrow \mathbb{R}$. We consider the map $X=\left(X_1, X_2\right): \Omega \rightarrow \mathbb{R}^2$, defined by $X(\omega)=\left(X_1(\omega), X_2(\omega)\right)$, which for any $\omega$ yields the respective tuple $\left(X_1(\omega), X_2(\omega)\right)$ and thus aligns quite naturally with the notion of a random vector. To justify this terminology, we need a $\sigma$-Algebra on $\mathbb{R^2}$ and there are two candidates that immediately come to mind. The Borel $\sigma$-Algebra generated by the open sets in $\mathbb{R}^2$ as in section 1.1, and, continuing our discussion of the previous section, the product $\sigma$-Algebra $\mathcal{B}(\mathbb{R}) \times \mathcal{B}(\mathbb{R})$.

### Proposition 5.8 Equivalence of Borel- and Product $\sigma$-Algebra
It holds that $\mathcal{B}\left(\mathbb{R}^2\right)=\mathcal{B}(\mathbb{R}) \times \mathcal{B}(\mathbb{R})$.
**Proof** The projections $\pi_i: \mathbb{R}^2 \rightarrow \mathbb{R}$ are continuous and thus $\mathcal{B}\left(\mathbb{R}^2\right)$-measurable. Since $\mathcal{B}(\mathbb{R}) \times \mathcal{B}(\mathbb{R})$ is the smallest $\sigma$-algebra for which the projections are measurable, we have $\mathcal{B}(\mathbb{R}) \times \mathcal{B}(\mathbb{R}) \subset \mathcal{B}\left(\mathbb{R}^2\right)$. Conversely, if $G$ is open in $\mathbb{R}^2$, it is the countable union of (open) rectangles in $\mathcal{R}$ (similar to the proof of Proposition 1.3) and hence $G \in \mathcal{B}(\mathbb{R}) \times \mathcal{B}(\mathbb{R})$, which yields the other inclusion.

### Remark 5.9 On Polish Spaces
Observe that proposition 5.8 generalizes to general topological spaces equipped with the Borel sets. For the proof of the reverse inclusion we used the fact that the real numbers are separable under the ordinary topology. Thus, our proposition holds for Polish spaces, but without equality, e.g. the strict inclusion of the product $\sigma$-Algebra in the Borel $\sigma$-Algebra on the product space (with the product topology).

Since we now know that $\mathcal{B}\left(\mathbb{R}^2\right)$ and $\mathcal{B}(\mathbb{R}) \times \mathcal{B}(\mathbb{R})$ are equivalent, we can use the term 2-dimensional random vector and arrive at the following corollary.

### Corollary 5.10 Random Vectors
Let $X_1, X_2:\Omega \rightarrow \mathbb{R}$ be given. The vector mapping $X=(X_1,X_2):\Omega \rightarrow \mathbb{R}^2$ is a random vector iff the $X_i$ are random variables.
**Proof**: Exercise 5.3

We already know that the sum of two arbitrary Random Variables $X_1, X_2$ is also a random variable. Let now $f:\mathbb{R}^2\rightarrow\mathbb{R}$ be a continuous function. Then it is also $\mathcal{B}\left(\mathbb{R}^2\right)$-measurable, and by 5.10 and composition of measurable functions $f(X_1, X_2)$ is a random variable as well. Take for example the trivial case $f(x_1, x_2) = x_1+x_2$. 
Recall that we defined in section [[Measure Theoretic Probability#3.2 Random Variables]] the distribution, or *law* of a random variable. Suppose now that $X=\left(X_1, X_2\right)$ is a random vector defined on $(\Omega, \mathcal{F}, \mathbb{P})$ with values in $\mathbb{R}^2$. Let $E \in \mathcal{B}\left(\mathbb{R}^2\right)$, then 
$$
\mathbb{P}^X(E):=\mathbb{P}(X \in E),
$$
for any $E \in \mathcal{B}\left(\mathbb{R}^2\right)$ defines a probability measure on $\left(\mathbb{R}^2, \mathcal{B}\left(\mathbb{R}^2\right)\right)$, the distribution of $X$, also called the joint distribution of $X_1, X_2$. Taking now $E=E_1 \times \mathbb{R}$, we obtain the marginal probability of $E_1$ as $\mathbb{P}^X\left(E_1 \times \mathbb{R}\right)=\mathbb{P}\left(X_1 \in E_1\right)=\mathbb{P}^{X_1}\left(E_1\right)$. Common terminology is to call $\mathbb{P}^{X_1}$ the marginal distribution, or marginal law, of $X_1$. 
Along with the joint distribution of $X$, we introduce the joint distribution function $F=F_X: \mathbb{R}^2 \rightarrow[0,1]$, given by
$$
F\left(x_1, x_2\right)=\mathbb{P}^X\left(\left(-\infty, x_1\right] \times\left(-\infty, x_2\right]\right)=\mathbb{P}\left(X_1 \leq x_1, X_2 \leq x_2\right) .
$$
Notice that we recover $F_{X_1}(x_1)$ from the limiting process $F_{X_1}\left(x_1\right)=\lim _{x_2 \rightarrow \infty} F\left(x_1, x_2\right)$, also denoted $F\left(x_1, \infty\right)$.
It may happen that there exists a nonnegative $\mathcal{B}\left(\mathbb{R}^2\right)$-measurable function $f$ such that 
$\mathbb{P}^X(E)=\int_E f \mathrm{~d}(\lambda \times \lambda)$, for all $E \in \mathcal{B}\left(\mathbb{R}^2\right)$. In that case, $f$ is called the *joint density* of $X$.
The obvious marginal density $f_{X_1}$ of $X_1$ is defined by $f_{X_1}\left(x_1\right)=\int f\left(x_1, x_2\right) \lambda\left(\mathrm{d} x_2\right)$. One similarly defines the marginal density of $X_2$. Check these are indeed densities in the sense of Example 4.29.

We recall how, in Chapter 3, we introduced independence in relation to the multiplication of probabilities. It should be natural to connect this with the idea of product measures.
### Proposition 5.12 Independence of Joint Random Variables
Two random variables $X_1, X_2$ on ( $\Omega, \mathcal{F}, \mathbb{P}$ ) are independent iff the joint distribution $\mathbb{P}^{\left(X_1, X_2\right)}$ is the product measure $\mathbb{P}^{X_1} \times \mathbb{P}^{X_2}$. This in turn happens iff $F\left(x_1, x_2\right)=F_{X_1}\left(x_1\right) F_{X_2}\left(x_2\right)$, for all $x_1, x_2 \in \mathbb{R}$. Assume further that ( $X_1, X_2$ ) has a joint probability density function $f$. Let $f_1$ and $f_2$ be the (marginal) probability density functions of $X_1$ and $X_2$ respectively. Then $X_1$ and $X_2$ are independent iff $f\left(x_1, x_2\right)=f_1\left(x_1\right) f_2\left(x_2\right)$ for all $\left(x_1, x_2\right)$ except in a set of $\lambda \times \lambda$-measure zero.
### Remark 5.13
Suppose one is given a random variable $X$, defined on a given $(\Omega, \mathcal{F}, \mathbb{P})$. Sometimes one needs an additional random variable $Y$ having a specified distribution. It may happen that the given probability space is not rich enough to have such a random variable well defined. Suppose $\Omega=\{0,1\}$ and $X(\omega)=\omega$, having a Bernoulli distribution for $\mathbb{P}$ defined on the power set of $\Omega$ with $\mathbb{P}(\{1\})=p$. Clearly, it is impossible to define on this $\Omega$ a random variable having more than two different outcomes. Extending the probability space to a suitable product space offers a way out, see Exercise 5.13, from which it even follows that $X$ and $Y$ are independent.

It is straightforward to generalize these ideas to higher dimensions, let us now take a look at the case of infinite products.  
### 5.3 Infinite Products
The extension of product spaces from finite to infinite products is a different matter.  Nevertheless this extension is inevitable if one wants to construct a well defined independent infinite sequence of random variables. These considerations are vital, since they will later allow us a rigorous construction of stochastic processes. Recall that we've seen so far, that the independence of two random variables has everything to do with product measures. An infinite sequence of independent random variables will therefore require an infinite product of probability measures. 

For real valued random variables we have already encountered a construction of a supporting probability space in Section 3.3. Here we continue with the construction of a **countable** product of probability spaces. 

Assume that for every $n \in \mathbb{N}$ we have a corresponding probability space $\left(\Omega_n, \mathcal{F}_n, \mathbb{P}_n\right)$. Let $\Omega=\prod_{n=1}^{\infty} \Omega_n$ and denote by $\omega=\left(\omega_1, \omega_2, \ldots\right)$ a typical element of $\Omega$. The construction of the product $\sigma$-Algebra remains the same as before. (we basically apply the $\Sigma$-Operator to the n-dimensional rectangles like at the beginning of the chapter.)
The projection $\pi_n: \Omega \rightarrow \Omega_n$ is defined by $\pi_n(\omega)=\omega_n$.
On the product set $\Omega$ we define the $\sigma$-Algebra $\mathcal{F}$ as the smallest such $\sigma$-Algebra that makes all projections $\pi_n$ measurable mappings. 

This is similar to defining a subbasis of the product topology. 

One can also define a multivariate projection $\pi_{(1, \ldots, n)}: \Omega \rightarrow \prod_{k=1}^n \Omega_k$ by $\pi_{(1, \ldots, n)}(\omega)=\left(\omega_1, \ldots, \omega_n\right)$ and it follows that all multivariate projections are $\mathcal{F}$-measurable as well. 

A **cylinder**, or **measurable rectangle**, is by definition the inverse image of a measurable set in some product space, endowed with the respective product $\sigma$-Algebra $\mathcal{F}_1 \times \cdots \times \mathcal{F}_n$ under the projection $\pi_{(1, \ldots, n)}$. 
It follows that a cylinder is of the type $B_n \times \prod_{k=n+1}^{\infty} \Omega_k$ (for some $n$ ), with $B_n \in \mathcal{F}_1 \times \cdots \times \mathcal{F}_n$. Such a cylinder will be denoted by $C_n$. Let $\mathcal{C}$ be the collection of all cylinders and note that $\mathcal{C}$ is an algebra. Define the mapping $\mathbb{P}_0: \mathcal{C} \rightarrow[0,1]$ by $\mathbb{P}_0(C)=\prod_{i=1}^n \mathbb{P}_i\left(B_n\right)$, if $C=C_n$ for some $n$. Verify that if one writes $C=C_m$ for some $m \neq n$, it holds that $\prod_{i=1}^n \mathbb{P}_i\left(B_n\right)=\prod_{i=1}^m \mathbb{P}_i\left(B_m\right)$, which implies that $\mathbb{P}_0$ is unambiguously defined, i.e. not depending on the chosen representation of $C$. Verify too that $\mathbb{P}_0$ is finitely additive on $\mathcal{C}$. The next theorem states the existence of an infinite product probability measure $\mathbb{P}$, sometimes denoted by $\prod_{n=1}^{\infty} \mathbb{P}_n$. In the proof we use results from Section 2.2.

### Theorem 5.14 Existence and uniqueness of infinite probability measures
There exists a unique probability measure $\mathbb{P}$ on $(\Omega, \mathcal{F})$ such that $\mathbb{P}$ restricted to the algebra $\mathcal{C}$ is equal to $\mathbb{P}_0$. In particular: 
$$
\mathbb{P}\left(E_1 \times \cdots \times E_n \times \prod_{k=n+1}^{\infty} \Omega_k\right)=\prod_{i=1}^n \mathbb{P}_i\left(E_i\right),
$$
if $E_i \in \mathcal{F}_i, i=1, \ldots, n$.
In essence this asserts that there exists a **unique probability measure** $\mathbb{P}$ on the infinite product space $(\Omega, \mathcal{F})$ such that, on finite-dimensional cylinders, it agrees with the obvious finite product measure. This is a special case of Kolmogorovs Extension Theorem https://en.wikipedia.org/wiki/Kolmogorov_extension_theorem that would even allow us to specify this notion of product spaces to uncountable index sets $T$, but we would have to restrict the measure to the product $\sigma$-Algebra $\left(\mathbb{R}^n\right)^T$ which is not very rich. 

We leave the proof as an application of Carathéodory's Extension Theorem to the reader.
# 6 Derivative of a Measure

The topics of this chapter are *absolute continuity* and *singularity* of a pair of measures. The central result is a kind of converse of Proposition 4.23, known as the **Radon-Nikodym Theorem**
We will work towards the full proof of this theorem by first proving some essential intermediary results. Let us start by providing the necessary terminology.

## 6.1 Linear Functionals on $\mathbb{R}^n$
Let $H=\mathbb{R}^n$. It is well known that every linear map $T: H \rightarrow \mathbb{R}^m$ can uniquely be represented by an $m \times n$ matrix $M=M(T)$ via $T(x)=M x$ (the usual product of matrix and a vector), which we will reprove below for the case $m=1$. Let $m=1$ and $\langle\cdot, \cdot\rangle$ be the usual inner product on $H,\langle x, y\rangle=x^{\top} y$. For this case the matrix $M$ becomes a row vector. For $y=M^{\top} \in \mathbb{R}^n$ one then has
$$
T(x)=\langle x, y\rangle \quad (6.1)
$$
Hence we can identify the mapping $T$ with the vector $y$. Let $H^*$ be the set of all linear maps on $H$. In this case we have the identification of $H^*$ with $H$ itself via the equation above. 
Basically, any linear function al can be written in the form of a vector or matrix. But $H^*$ is itself a vector space, we can add functionals and scale them by some constant etc. So these spaces are isomorphic -- we can define a bijection between them.
Suppose we know that $T(x)=\langle x, y\rangle$ holds. Then the **Kernel** K of T is the space of vectors that are orthogonal to y and the **orthogonal complement** of K is the space of all vectors that are multiples of y.  We use this to prove 6.1 as follows: 
Let $T\neq0$. Then the kernel $K$ of $T$ is a proper linear subspace of $H$. Take any nonzero vector $z$ in the orthogonal complement of $K$, a one-dimensional linear subspace of $H$. Every vector $x$ can therefore be written as a sum $x=\lambda z+u$, with $\lambda \in \mathbb{R}$ and $u \in K$. Therefore: 
$$
\lambda=\frac{\langle x, z\rangle}{\langle z, z\rangle} \text { and } T(x)=\lambda T(z) .
$$
Let $y=\frac{T(z)}{\langle z, z\rangle} z$. Then $\langle x, y\rangle=\frac{T(z)}{\langle z, z\rangle}\langle x, z\rangle=\lambda T(z)=T(x)$, as follows from (6.2). Uniqueness of $y$ is shown as follows. Let $y^{\prime} \in H$ be such that $T(x)=\left\langle{x, y^{\prime}}\right\rangle$. Then $\left\langle x, y-y^{\prime}\right\rangle$ is zero for all $x \in H$, in particular for $x=y-y^{\prime}$. But then $y-y^{\prime}$ must be the zero vector. 

The key observation is now, that this proof carries over to the case where we're working with continuous linear functionals on a Hilbert space.
## 6.2 Linear Functionals on a Hilbert Space

Let $H$ be a (real) Hilbert space, a vector space over the real numbers, endowed with an inner product $\langle\cdot, \cdot\rangle$, that is complete w.r.t. the norm $\|\cdot\|$ generated by this inner product. 
Let $T: H \rightarrow \mathbb{R}$ be a continuous linear functional on $H$. There exists a $C \geq 0$ such that $|T x| \leq C\|x\|$ for all $x \in H$. We denote by $H^*$ the linear space of all continuous linear functionals on $H$, also called the dual space of $H$. We will prove the *Riesz-Fréchet* theorem, stating that every continuous linear functional on $H$ is given by an inner product with a fixed element of $H$.

### Theorem 6.1: Riesz-Fréchet
Let $T\in H^*$. Then there exists a unique element $y$ in $H$ such that $Tx=\langle x ,y\rangle$. 
Proof given in original script. 

This theorem basically equips us with the following: It tells us that linear functionals are just inner products with vectors. This allows us to move comfortably between *maps* and *elements*. This is particularly relevant for Radon-Nikodym since In $L^2(\mu)$ the functional $T_g(f)=\int f g d \mu$ is exactly the inner product $T_g(f)=\langle f, g\rangle_{L^2(\mu)}$, where in the case for absolutely continuous measures $\nu \ll \mu$ Radon-Nikodym will guarantee that there exists a function $f \in L^1(\mu)$ such that $\nu(A)=\int_A f d \mu \quad \forall A$.
So we can represent a measure as an inner product of the indicator of $A$ with $f$, which is of course nothing but the integral. 

## 6.4 Absolute Continuity and Singularity
### 6.5 Definition
Let $\mu$ be a positive measure and $\nu$ a complex or positive measure on a measurable space $(S, \Sigma)$. We say that $\nu$ is absolutely continuous w.r.t. $\mu$ (Notation: $\nu \ll \mu$.) if $\nu(E)=0$ for every $E \in \Sigma$ with $\mu(E)=0$. (If both measures agree on every $\mu$-null set of $\Sigma$, $\nu$ has no "extra mass" where $\mu$ sees nothing.) 

Two arbitrary measures $\mu$ and $\nu$ are called mutually singular (Notation: $\nu \perp \mu$) if there exist disjoint sets $E$ and $F$ in $\Sigma$ such that $\nu(A)=\nu(A \cap E)$ and $\mu(A)=\mu(A \cap F)$ for all $A \in \Sigma$. ($\nu$ is entirely concentrated on E, and $\mu$ is entirely concentrated on F. The supports of both measures are mutually disjoint. )

### Proposition 6.6 Rechenregeln
Let $\mu$ be a positive measure and $\nu_1, \nu_2$ arbitrary measures, all defined on the same measurable space. Then the following properties hold true.
	(i) If $\nu_1 \perp \mu$ and $\nu_2 \perp \mu$, then $\nu_1+\nu_2 \perp \mu$.
	(ii) If $\nu_1 \ll \mu$ and $\nu_2 \ll \mu$, then $\nu_1+\nu_2 \ll \mu$.
	(iii) If $\nu_1 \ll \mu$ and $\nu_2 \perp \mu$, then $\nu_1 \perp \nu_2$.
	(iv) If $\nu_1 \ll \mu$ and $\nu_1 \perp \mu$, then $\nu_1=0$.

### Proposition 6.7 Uniqueness of Lebesgue Decomposition
Given a positive measure $\mu$ and any other measure $\nu$ we can always find a decomposition $\nu_a \ll \mu$ and $\nu_s \perp \mu$. of $\nu$.

## 6.5 The Radon-Nikodym Theorem
As an appetizer for the Radon-Nikodym theorem we consider a special case. Let $S$ be a finite or countable set and $\Sigma = 2^S$. Let $\mu$ be a positive $\sigma$-finite measure on $(S, \Sigma)$ and $\nu$ another finite measure such that $\nu \ll \mu$. Define $h(x)=\frac{\nu(\{x\})}{\mu(\{x\})}$ if $\mu(\{x\})>0$ and zero otherwise. It is easy to verify that $h \in \mathcal{L}^1(S, \Sigma, \mu)$ and $\nu(E)=\mu\left(\mathbf{1}_E h\right), \forall E \subset S$.
In this finite or countable case the "little version" of RN-Theorem states that we can obtain one measure by reweighting the other with a suitable density h over the non-nullsets. 

The principal theorem on absolute continuity (and singularity) is the following: 

### The Radon-Nikodym Theorem
Let $\mu$ be a positive $\sigma$-finite measure and $\nu$ a complex measure. Then there exists a unique decomposition $\nu=\nu_a+\nu_s$ and a function $h \in \mathcal{L}^1(S, \Sigma, \mu)$ such that $\nu_a(E)=\mu\left(\mathbf{1}_E h\right)$ for all $E \in \Sigma$ (so $\nu_a \ll \mu$ ) and $\nu_s \perp \mu$. Moreover, $h$ is unique in the sense that any other $h^{\prime}$ with this property is such that $\mu\left(\left\{h \neq h^{\prime}\right\}\right)=0$. The function $h$ is called the Radon-Nikodym derivative of $\nu_a$ w.r.t. $\mu$ and is often written as
$$
h=\frac{\mathrm{d} \nu_a}{\mathrm{~d} \mu}
$$
Radon Nikodym derivatives are unique up to $\mu$-null sets, probability density functions are only defined almost everywhere. 

### Remark 6.11
If $\nu$ is a positive $\sigma$-finite measure, then the Radon-Nikodym theorem is still true with the exception thatwe only have $\mu(h1_{s_n})\lt \inf$, where the $S_n$ form a measurable partition of $S$ such that $\nu\left(S_n\right)<\infty$ for all $n$. Notice that in this case we may still take $h \geq 0$.

### Remark 6.12 The Radon Nikodym Derivative
The function $h$ of the RN-Theorem, the Radon-Nikodym derivative of $\nu_a$ w.r.t. $\mu$ is also called the **density** of $\nu_a$ w.r.t. $\mu$. If $\lambda$ is the Lebesgue measure on ( $\mathbb{R}, \mathcal{B}$ ) and $\nu$ is the law of a random variable $X$ that is absolutely continuous w.r.t. $\lambda$ we have that 
$$
F(x):=\nu((-\infty, x])=\int_{(-\infty, x]} f \mathrm{~d} \lambda, \text { where } f=\frac{\mathrm{d} \nu}{\mathrm{~d} \lambda} .
$$
Traditionally, the function $f$ was called the density of $X$, and we see that calling a Radon-Nikodym derivative a density is in agreement with this tradition, but also extends it. 

## 6.6 Decomposition of a Distribution Function
In elementary probability one often distinguishes between distribution functions that are of pure jump type (discrete random variables) and those that admit and ordinary distribution. These can both be recognized as examples of the following result.

### Proposition 6.13: Decomposition of a Distribution Function
Let $F$ be a distribution function, $F: \mathbb{R}\rightarrow \mathbb{R}$. Then there exists a purely discontinuous right-continuous nondecreasing function $F_d$ with  $\lim _{x \rightarrow-\infty} F_d(x)=0$, a nonnegative Borel-measurable function $f$ and a nondecreasing continuous function $F_s$ with $\lim _{x \rightarrow-\infty} F_s(x)=0$ such that the decomposition 
$$
F=F_d+F_s+F_{a c}
$$
holds true, with $F_{a c}$ defined by $F_{a c}(x)=\int_{-\infty}^x f(y) \mathrm{d} y$. Such a decomposition is unique.

In essence this states that we can split any distribution function mapping from $\mathbb{R}$ to $\mathbb{R}$ into three "mutually orthogonal" parts: 
	A purely discontinuous jump function, encoding the point masses of the function
	An absolutely continuous function, the "smooth part" of F w.r.t. Lebesgue measure
	A singular, continuous part, nondecreasing yet continuous and *singular* w.r.t. Lebesgue measure (increases only on a set of Lebesgue measure zero (Cantor distribution function))

Example for the third part that is most unintuitive: The Cantor distribution. 
### The Cantor Distribution
The Cantor distribution is the probability distribution whose cumulative distribution function is the Cantor function. It has neither a pdf nor a pmf, since although its cumulative distribution function is a continuous function, the distribution is not absolutely continuous w.r.t. Lebesgue measure, nor does it have any point-masses. (So the decomposition would consist only of F_s?). It is thus neither a discrete nor an absolutely continuous probability distribution, nor is it a mixture of these, rather an example of a singular distribution. 
Its cumulative distribution function is continuous everywhere but horizontal almost everywhere. 

### Exercise 6.10
Let $\mu$ be a real measure on a space $(S, \Sigma)$. Define $\nu: \Sigma \rightarrow [0, \inf)$ by $\nu(E)=\sup \{\mu(F): F \in \Sigma, F \subset E, \mu(F) \geq 0\}$.
Show that $\nu$ is a finite positive measure, Give a characterization of $\nu$.
(Hahn decomposition & Measure properties)

# 7 Convergence and Uniform Integrability
In this chapter we first review a number of convergence concepts for random variables and study how they are interrelated. The important concept of uniform integrability shall enable us to perform a more refined analysis.
## 7.1 Modes of Convergence



# 8 Conditional Expectation
## asdf


# 9 Martingales and their Relatives

# 10 Convergence Theorems

# 11 Weak Convergence

# 12 Characteristic Functions


