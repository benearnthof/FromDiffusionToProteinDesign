Attentive Language Models Beyond a Fixed-Length Context
https://arxiv.org/pdf/1901.02860