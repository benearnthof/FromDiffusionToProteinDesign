Mixture of Block Attention for Long-Context LLMs
https://arxiv.org/abs/2502.13189


[[XAttention]]